Linux sandbox 3.13.0-100-generic #147-Ubuntu SMP Tue Oct 18 16:48:51 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
Ign http://archive.ubuntu.com trusty InRelease
Hit http://archive.ubuntu.com trusty-updates InRelease
Hit http://archive.ubuntu.com trusty-security InRelease
Hit http://archive.ubuntu.com trusty Release.gpg
Hit http://archive.ubuntu.com trusty Release
Hit http://archive.ubuntu.com trusty-updates/main Sources
Hit http://archive.ubuntu.com trusty-updates/restricted Sources
Hit http://archive.ubuntu.com trusty-updates/universe Sources
Hit http://archive.ubuntu.com trusty-updates/main amd64 Packages
Hit http://archive.ubuntu.com trusty-updates/restricted amd64 Packages
Hit http://archive.ubuntu.com trusty-updates/universe amd64 Packages
Hit http://archive.ubuntu.com trusty-security/main Sources
Hit http://archive.ubuntu.com trusty-security/restricted Sources
Hit http://archive.ubuntu.com trusty-security/universe Sources
Hit http://archive.ubuntu.com trusty-security/main amd64 Packages
Hit http://archive.ubuntu.com trusty-security/restricted amd64 Packages
Hit http://archive.ubuntu.com trusty-security/universe amd64 Packages
Hit http://archive.ubuntu.com trusty/main Sources
Hit http://archive.ubuntu.com trusty/restricted Sources
Hit http://archive.ubuntu.com trusty/universe Sources
Hit http://archive.ubuntu.com trusty/main amd64 Packages
Hit http://archive.ubuntu.com trusty/restricted amd64 Packages
Hit http://archive.ubuntu.com trusty/universe amd64 Packages
Reading package lists...

WARNING: apt does not have a stable CLI interface yet. Use with caution in scripts.

Reading package lists...
Building dependency tree...
Reading state information...
git is already the newest version.
0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.
mkdir: cannot create directory '/root/': File exists
fatal: destination path 'griffin-sample' already exists and is not an empty directory.
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   644    0   644    0     0    953      0 --:--:-- --:--:-- --:--:--   955
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0  149M    0  117k    0     0  59340      0  0:44:04  0:00:02  0:44:02  113k  0  149M    0  628k    0     0   207k      0  0:12:17  0:00:03  0:12:14  308k  0  149M    0 1477k    0     0   366k      0  0:06:57  0:00:04  0:06:53  486k  1  149M    1 2379k    0     0   481k      0  0:05:18  0:00:04  0:05:14  601k  2  149M    2 3076k    0     0   514k      0  0:04:57  0:00:05  0:04:52  615k  2  149M    2 3619k    0     0   518k      0  0:04:55  0:00:06  0:04:49  706k  2  149M    2 4045k    0     0   506k      0  0:05:02  0:00:07  0:04:55  689k  2  149M    2 4469k    0     0   497k      0  0:05:07  0:00:08  0:04:59  603k  3  149M    3 4809k    0     0   483k      0  0:05:16  0:00:09  0:05:07  486k  3  149M    3 5252k    0     0   478k      0  0:05:20  0:00:10  0:05:10  435k  3  149M    3 5677k    0     0   473k      0  0:05:23  0:00:11  0:05:12  411k  3  149M    3 6085k    0     0   468k      0  0:05:26  0:00:12  0:05:14  408k  4  149M    4 6476k    0     0   464k      0  0:05:29  0:00:13  0:05:16  404k  4  149M    4 7054k    0     0   472k      0  0:05:24  0:00:14  0:05:10  449k  5  149M    5 7666k    0     0   480k      0  0:05:18  0:00:15  0:05:03  486k  5  149M    5 8210k    0     0   484k      0  0:05:16  0:00:16  0:05:00  510k  5  149M    5 8873k    0     0   494k      0  0:05:09  0:00:17  0:04:52  561k  6  149M    6 9654k    0     0   509k      0  0:05:00  0:00:18  0:04:42  635k  6  149M    6 10.2M    0     0   524k      0  0:04:52  0:00:19  0:04:33  680k  7  149M    7 10.9M    0     0   533k      0  0:04:47  0:00:20  0:04:27  700k  7  149M    7 11.5M    0     0   538k      0  0:04:44  0:00:21  0:04:23  719k  8  149M    8 12.1M    0     0   543k      0  0:04:42  0:00:22  0:04:20  716k  8  149M    8 12.8M    0     0   548k      0  0:04:39  0:00:23  0:04:16  693k  8  149M    8 13.4M    0     0   551k      0  0:04:37  0:00:24  0:04:13  659k  9  149M    9 14.0M    0     0   555k      0  0:04:35  0:00:25  0:04:10  649k  9  149M    9 14.8M    0     0   563k      0  0:04:31  0:00:26  0:04:05  673k 10  149M   10 15.5M    0     0   567k      0  0:04:29  0:00:27  0:04:02  680k 10  149M   10 16.2M    0     0   572k      0  0:04:27  0:00:28  0:03:59  690k 11  149M   11 16.9M    0     0   578k      0  0:04:24  0:00:29  0:03:55  714k 11  149M   11 17.6M    0     0   582k      0  0:04:22  0:00:30  0:03:52  723k 12  149M   12 18.3M    0     0   588k      0  0:04:20  0:00:31  0:03:49  720k 12  149M   12 19.3M    0     0   600k      0  0:04:15  0:00:32  0:03:43  782k 13  149M   13 20.2M    0     0   611k      0  0:04:10  0:00:33  0:03:37  833k 14  149M   14 21.0M    0     0   617k      0  0:04:08  0:00:34  0:03:34  850k 14  149M   14 21.9M    0     0   623k      0  0:04:05  0:00:35  0:03:30  876k 15  149M   15 22.7M    0     0   631k      0  0:04:02  0:00:36  0:03:26  907k 15  149M   15 23.6M    0     0   637k      0  0:04:00  0:00:37  0:03:23  884k 16  149M   16 24.3M    0     0   640k      0  0:03:59  0:00:38  0:03:21  839k 16  149M   16 25.1M    0     0   645k      0  0:03:57  0:00:39  0:03:18  839k 17  149M   17 25.9M    0     0   649k      0  0:03:55  0:00:40  0:03:15  833k 17  149M   17 26.7M    0     0   652k      0  0:03:54  0:00:41  0:03:13  809k 18  149M   18 27.6M    0     0   658k      0  0:03:52  0:00:42  0:03:10  819k 19  149M   19 28.5M    0     0   663k      0  0:03:50  0:00:43  0:03:07  846k 19  149M   19 29.2M    0     0   667k      0  0:03:49  0:00:44  0:03:05  844k 20  149M   20 30.4M    0     0   678k      0  0:03:45  0:00:45  0:03:00  917k 21  149M   21 31.5M    0     0   687k      0  0:03:42  0:00:46  0:02:56  979k 21  149M   21 32.5M    0     0   695k      0  0:03:40  0:00:47  0:02:53 1010k 22  149M   22 33.5M    0     0   700k      0  0:03:38  0:00:48  0:02:50 1029k 23  149M   23 34.7M    0     0   711k      0  0:03:35  0:00:49  0:02:46 1109k 23  149M   23 35.9M    0     0   721k      0  0:03:32  0:00:50  0:02:42 1118k 24  149M   24 36.9M    0     0   729k      0  0:03:30  0:00:51  0:02:39 1121k 25  149M   25 37.9M    0     0   734k      0  0:03:28  0:00:52  0:02:36 1107k 25  149M   25 38.8M    0     0   738k      0  0:03:27  0:00:53  0:02:34 1105k 26  149M   26 39.8M    0     0   742k      0  0:03:26  0:00:54  0:02:32 1049k 27  149M   27 40.8M    0     0   747k      0  0:03:25  0:00:55  0:02:30 1006k 27  149M   27 41.8M    0     0   751k      0  0:03:23  0:00:56  0:02:27  982k 28  149M   28 42.6M    0     0   753k      0  0:03:23  0:00:57  0:02:26  958k 28  149M   28 43.3M    0     0   753k      0  0:03:23  0:00:58  0:02:25  911k 29  149M   29 44.1M    0     0   753k      0  0:03:23  0:00:59  0:02:24  877k 29  149M   29 44.8M    0     0   754k      0  0:03:23  0:01:00  0:02:23  830k 30  149M   30 45.6M    0     0   754k      0  0:03:23  0:01:01  0:02:22  786k 30  149M   30 46.3M    0     0   753k      0  0:03:23  0:01:02  0:02:21  750k 31  149M   31 47.0M    0     0   753k      0  0:03:23  0:01:03  0:02:20  760k 31  149M   31 47.8M    0     0   754k      0  0:03:23  0:01:04  0:02:19  767k 32  149M   32 48.6M    0     0   754k      0  0:03:23  0:01:05  0:02:18  763k 33  149M   33 49.3M    0     0   755k      0  0:03:22  0:01:06  0:02:16  769k 33  149M   33 50.1M    0     0   755k      0  0:03:22  0:01:07  0:02:15  785k 34  149M   34 50.9M    0     0   756k      0  0:03:22  0:01:08  0:02:14  792k 34  149M   34 51.9M    0     0   760k      0  0:03:21  0:01:09  0:02:12  836k 35  149M   35 52.9M    0     0   764k      0  0:03:20  0:01:10  0:02:10  887k 35  149M   35 53.8M    0     0   766k      0  0:03:20  0:01:11  0:02:09  908k 36  149M   36 54.6M    0     0   766k      0  0:03:19  0:01:12  0:02:07  914k 37  149M   37 55.5M    0     0   768k      0  0:03:19  0:01:13  0:02:06  939k 37  149M   37 56.6M    0     0   774k      0  0:03:17  0:01:14  0:02:03  965k 38  149M   38 57.7M    0     0   778k      0  0:03:16  0:01:15  0:02:01  986k 39  149M   39 58.8M    0     0   783k      0  0:03:15  0:01:16  0:01:59 1030k 40  149M   40 59.9M    0     0   787k      0  0:03:14  0:01:17  0:01:57 1087k 40  149M   40 61.0M    0     0   791k      0  0:03:13  0:01:18  0:01:55 1134k 41  149M   41 62.5M    0     0   800k      0  0:03:11  0:01:19  0:01:52 1203k 42  149M   42 63.9M    0     0   809k      0  0:03:09  0:01:20  0:01:49 1269k 43  149M   43 65.3M    0     0   817k      0  0:03:07  0:01:21  0:01:46 1337k 44  149M   44 66.9M    0     0   826k      0  0:03:05  0:01:22  0:01:43 1430k 45  149M   45 68.3M    0     0   833k      0  0:03:03  0:01:23  0:01:40 1484k 46  149M   46 69.6M    0     0   839k      0  0:03:02  0:01:24  0:01:38 1454k 47  149M   47 70.8M    0     0   844k      0  0:03:01  0:01:25  0:01:36 1415k 48  149M   48 72.1M    0     0   849k      0  0:03:00  0:01:26  0:01:34 1374k 49  149M   49 73.3M    0     0   853k      0  0:02:59  0:01:27  0:01:32 1312k 49  149M   49 74.5M    0     0   858k      0  0:02:58  0:01:28  0:01:30 1278k 50  149M   50 75.7M    0     0   862k      0  0:02:57  0:01:29  0:01:28 1251k 51  149M   51 77.0M    0     0   867k      0  0:02:56  0:01:30  0:01:26 1258k 52  149M   52 78.3M    0     0   872k      0  0:02:55  0:01:31  0:01:24 1278k 53  149M   53 79.5M    0     0   876k      0  0:02:54  0:01:32  0:01:22 1282k 53  149M   53 80.7M    0     0   880k      0  0:02:54  0:01:33  0:01:21 1271k 54  149M   54 81.8M    0     0   882k      0  0:02:53  0:01:34  0:01:19 1251k 55  149M   55 83.0M    0     0   886k      0  0:02:52  0:01:35  0:01:17 1244k 56  149M   56 84.2M    0     0   889k      0  0:02:52  0:01:36  0:01:16 1206k 57  149M   57 85.3M    0     0   892k      0  0:02:51  0:01:37  0:01:14 1185k 57  149M   57 86.5M    0     0   895k      0  0:02:51  0:01:38  0:01:13 1175k 58  149M   58 87.7M    0     0   898k      0  0:02:50  0:01:39  0:01:11 1198k 59  149M   59 88.8M    0     0   901k      0  0:02:50  0:01:40  0:01:10 1178k 60  149M   60 90.0M    0     0   904k      0  0:02:49  0:01:41  0:01:08 1182k 60  149M   60 91.0M    0     0   905k      0  0:02:49  0:01:42  0:01:07 1156k 61  149M   61 92.0M    0     0   906k      0  0:02:49  0:01:43  0:01:06 1124k 62  149M   62 92.9M    0     0   907k      0  0:02:48  0:01:44  0:01:04 1077k 62  149M   62 94.0M    0     0   908k      0  0:02:48  0:01:45  0:01:03 1060k 63  149M   63 95.2M    0     0   911k      0  0:02:48  0:01:46  0:01:02 1071k 64  149M   64 96.6M    0     0   916k      0  0:02:47  0:01:47  0:01:00 1142k 65  149M   65 97.9M    0     0   920k      0  0:02:46  0:01:48  0:00:58 1210k 66  149M   66 99.1M    0     0   922k      0  0:02:46  0:01:49  0:00:57 1254k 66  149M   66  100M    0     0   924k      0  0:02:45  0:01:50  0:00:55 1254k 67  149M   67  101M    0     0   926k      0  0:02:45  0:01:51  0:00:54 1230k 68  149M   68  102M    0     0   927k      0  0:02:45  0:01:52  0:00:53 1166k 69  149M   69  103M    0     0   929k      0  0:02:44  0:01:53  0:00:51 1128k 69  149M   69  104M    0     0   930k      0  0:02:44  0:01:54  0:00:50 1090k 70  149M   70  105M    0     0   932k      0  0:02:44  0:01:55  0:00:49 1104k 71  149M   71  106M    0     0   933k      0  0:02:44  0:01:56  0:00:48 1100k 72  149M   72  107M    0     0   935k      0  0:02:43  0:01:57  0:00:46 1114k 72  149M   72  108M    0     0   936k      0  0:02:43  0:01:58  0:00:45 1107k 73  149M   73  109M    0     0   938k      0  0:02:43  0:01:59  0:00:44 1127k 74  149M   74  110M    0     0   937k      0  0:02:43  0:02:00  0:00:43 1070k 74  149M   74  111M    0     0   937k      0  0:02:43  0:02:01  0:00:42 1033k 75  149M   75  112M    0     0   938k      0  0:02:43  0:02:02  0:00:41 1019k 76  149M   76  113M    0     0   940k      0  0:02:42  0:02:03  0:00:39 1029k 76  149M   76  114M    0     0   942k      0  0:02:42  0:02:04  0:00:38 1026k 77  149M   77  115M    0     0   942k      0  0:02:42  0:02:05  0:00:37 1067k 78  149M   78  117M    0     0   944k      0  0:02:42  0:02:06  0:00:36 1101k 78  149M   78  118M    0     0   944k      0  0:02:42  0:02:07  0:00:35 1094k 79  149M   79  119M    0     0   945k      0  0:02:42  0:02:08  0:00:34 1067k 80  149M   80  120M    0     0   946k      0  0:02:41  0:02:09  0:00:32 1050k 80  149M   80  121M    0     0   946k      0  0:02:41  0:02:10  0:00:31 1043k 81  149M   81  122M    0     0   947k      0  0:02:41  0:02:11  0:00:30 1026k 82  149M   82  123M    0     0   948k      0  0:02:41  0:02:12  0:00:29 1033k 82  149M   82  124M    0     0   948k      0  0:02:41  0:02:13  0:00:28 1022k 83  149M   83  124M    0     0   948k      0  0:02:41  0:02:14  0:00:27 1003k 84  149M   84  125M    0     0   948k      0  0:02:41  0:02:15  0:00:26  996k 85  149M   85  127M    0     0   951k      0  0:02:41  0:02:16  0:00:25 1053k 85  149M   85  128M    0     0   953k      0  0:02:40  0:02:17  0:00:23 1090k 86  149M   86  129M    0     0   955k      0  0:02:40  0:02:18  0:00:22 1142k 87  149M   87  130M    0     0   957k      0  0:02:40  0:02:19  0:00:21 1199k 88  149M   88  131M    0     0   957k      0  0:02:39  0:02:20  0:00:19 1209k 88  149M   88  132M    0     0   958k      0  0:02:39  0:02:21  0:00:18 1165k 89  149M   89  133M    0     0   958k      0  0:02:39  0:02:22  0:00:17 1100k 90  149M   90  134M    0     0   959k      0  0:02:39  0:02:23  0:00:16 1083k 90  149M   90  135M    0     0   960k      0  0:02:39  0:02:24  0:00:15 1050k 91  149M   91  136M    0     0   960k      0  0:02:39  0:02:25  0:00:14 1022k 92  149M   92  137M    0     0   960k      0  0:02:39  0:02:26  0:00:13  999k 92  149M   92  138M    0     0   958k      0  0:02:39  0:02:27  0:00:12  972k 93  149M   93  139M    0     0   956k      0  0:02:40  0:02:28  0:00:12  863k 93  149M   93  139M    0     0   954k      0  0:02:40  0:02:29  0:00:11  788k 93  149M   93  140M    0     0   953k      0  0:02:40  0:02:30  0:00:10  747k 94  149M   94  141M    0     0   951k      0  0:02:41  0:02:31  0:00:10  697k 94  149M   94  141M    0     0   950k      0  0:02:41  0:02:32  0:00:09  690k 95  149M   95  142M    0     0   949k      0  0:02:41  0:02:33  0:00:08  724k 95  149M   95  143M    0     0   948k      0  0:02:41  0:02:34  0:00:07  754k 96  149M   96  144M    0     0   947k      0  0:02:41  0:02:35  0:00:06  785k 97  149M   97  145M    0     0   947k      0  0:02:41  0:02:36  0:00:05  819k 97  149M   97  145M    0     0   945k      0  0:02:42  0:02:37  0:00:05  815k 98  149M   98  146M    0     0   944k      0  0:02:42  0:02:38  0:00:04  808k 98  149M   98  147M    0     0   943k      0  0:02:42  0:02:39  0:00:03  795k 98  149M   98  148M    0     0   942k      0  0:02:42  0:02:40  0:00:02  774k 99  149M   99  148M    0     0   941k      0  0:02:42  0:02:41  0:00:01  754k100  149M  100  149M    0     0   940k      0  0:02:42  0:02:42 --:--:--  774k
17/08/11 03:02:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/11 03:03:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
put: `/griffin/data/enum-profiling-sample/test_src.avro': File exists
17/08/11 03:03:01 INFO profile.ProfileApplication: ===============begin================
17/08/11 03:03:02 INFO batch.Application$: [Ljava.lang.String;@5bda8e08
17/08/11 03:03:02 INFO batch.Application$: env.json
17/08/11 03:03:02 INFO batch.Application$: {"name":"profileEnum_1502420581895_White","type":"profile","source":{"type":"avro","version":"1.7","config":{"file.name":"hdfs:///griffin/data/enum-profiling-sample/test_src.avro"}},"evaluateRule":{"sampleRatio":1,"rules":"$source.race == 'White'"}}
17/08/11 03:03:02 INFO batch.Application$: params validation pass
17/08/11 03:03:02 INFO spark.SparkContext: Running Spark version 1.6.0
17/08/11 03:03:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/11 03:03:03 WARN spark.SparkConf: 
SPARK_JAVA_OPTS was detected (set to '-Dspark.driver.port=53411').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
17/08/11 03:03:03 WARN spark.SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:03:03 WARN spark.SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:03:03 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:03:03 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:03:03 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:03:03 INFO util.Utils: Successfully started service 'sparkDriver' on port 53411.
17/08/11 03:03:04 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/08/11 03:03:04 INFO Remoting: Starting remoting
17/08/11 03:03:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.17.0.2:53412]
17/08/11 03:03:04 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 53412.
17/08/11 03:03:04 INFO spark.SparkEnv: Registering MapOutputTracker
17/08/11 03:03:04 INFO spark.SparkEnv: Registering BlockManagerMaster
17/08/11 03:03:04 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-0084a539-9be9-4f7c-a67c-7cef5642dd76
17/08/11 03:03:04 INFO storage.MemoryStore: MemoryStore started with capacity 511.1 MB
17/08/11 03:03:04 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/08/11 03:03:04 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:03:04 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
17/08/11 03:03:04 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/08/11 03:03:04 INFO ui.SparkUI: Started SparkUI at http://172.17.0.2:4040
17/08/11 03:03:04 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-a60fca4a-e556-4cf5-b2b6-85b8a698ebb5
17/08/11 03:03:04 INFO spark.HttpServer: Starting HTTP Server
17/08/11 03:03:04 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:03:04 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53438
17/08/11 03:03:04 INFO util.Utils: Successfully started service 'HTTP file server' on port 53438.
17/08/11 03:03:05 INFO spark.SparkContext: Added JAR file:/root/griffin-sample/enum-profiling-sample/sample/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar at http://172.17.0.2:53438/jars/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1502420585828
17/08/11 03:03:06 INFO client.RMProxy: Connecting to ResourceManager at sandbox/172.17.0.2:8032
17/08/11 03:03:06 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
17/08/11 03:03:06 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
17/08/11 03:03:06 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/08/11 03:03:06 INFO yarn.Client: Setting up container launch context for our AM
17/08/11 03:03:06 INFO yarn.Client: Setting up the launch environment for our AM container
17/08/11 03:03:06 INFO yarn.Client: Preparing resources for our AM container
17/08/11 03:03:06 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs:/home/spark_lib/spark-assembly-1.6.0-hadoop2.6.0.jar
17/08/11 03:03:06 INFO yarn.Client: Uploading resource file:/apache/spark/conf/hive-site.xml -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0059/hive-site.xml
17/08/11 03:03:06 INFO yarn.Client: Uploading resource file:/tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/__spark_conf__3673791526146036185.zip -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0059/__spark_conf__3673791526146036185.zip
17/08/11 03:03:07 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:03:07 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:03:07 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:03:07 INFO yarn.Client: Submitting application 59 to ResourceManager
17/08/11 03:03:07 INFO impl.YarnClientImpl: Submitted application application_1500434006041_0059
17/08/11 03:03:08 INFO yarn.Client: Application report for application_1500434006041_0059 (state: ACCEPTED)
17/08/11 03:03:08 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1502420587040
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0059/
	 user: root
17/08/11 03:03:09 INFO yarn.Client: Application report for application_1500434006041_0059 (state: ACCEPTED)
17/08/11 03:03:10 INFO yarn.Client: Application report for application_1500434006041_0059 (state: ACCEPTED)
17/08/11 03:03:10 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/08/11 03:03:10 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> sandbox, PROXY_URI_BASES -> http://sandbox:8088/proxy/application_1500434006041_0059), /proxy/application_1500434006041_0059
17/08/11 03:03:10 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/08/11 03:03:11 INFO yarn.Client: Application report for application_1500434006041_0059 (state: RUNNING)
17/08/11 03:03:11 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.17.0.2
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1502420587040
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0059/
	 user: root
17/08/11 03:03:11 INFO cluster.YarnClientSchedulerBackend: Application application_1500434006041_0059 has started running.
17/08/11 03:03:11 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46192.
17/08/11 03:03:11 INFO netty.NettyBlockTransferService: Server created on 46192
17/08/11 03:03:11 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/08/11 03:03:11 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.17.0.2:46192 with 511.1 MB RAM, BlockManagerId(driver, 172.17.0.2, 46192)
17/08/11 03:03:11 INFO storage.BlockManagerMaster: Registered BlockManager
17/08/11 03:03:19 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sandbox:41693) with ID 1
17/08/11 03:03:19 INFO storage.BlockManagerMasterEndpoint: Registering block manager sandbox:38392 with 511.1 MB RAM, BlockManagerId(1, sandbox, 38392)
17/08/11 03:03:19 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/08/11 03:03:20 INFO hive.HiveContext: Initializing execution hive, version 1.2.1
17/08/11 03:03:20 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:03:20 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:03:21 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/08/11 03:03:21 INFO metastore.ObjectStore: ObjectStore, initialize called
17/08/11 03:03:21 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/08/11 03:03:21 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/08/11 03:03:22 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/08/11 03:03:23 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:23 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:24 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:24 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:24 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/08/11 03:03:24 INFO metastore.ObjectStore: Initialized ObjectStore
17/08/11 03:03:25 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/08/11 03:03:25 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
17/08/11 03:03:25 INFO metastore.HiveMetaStore: Added admin role in metastore
17/08/11 03:03:25 INFO metastore.HiveMetaStore: Added public role in metastore
17/08/11 03:03:25 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
17/08/11 03:03:25 INFO metastore.HiveMetaStore: 0: get_all_databases
17/08/11 03:03:25 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=get_all_databases	
17/08/11 03:03:25 INFO metastore.HiveMetaStore: 0: get_functions: db=default pat=*
17/08/11 03:03:25 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/08/11 03:03:25 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:25 INFO session.SessionState: Created local directory: /tmp/root_resources
17/08/11 03:03:25 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/4c6cef6e-5f7d-44c4-9db1-5da748e9f37a
17/08/11 03:03:25 INFO session.SessionState: Created local directory: /tmp/root/4c6cef6e-5f7d-44c4-9db1-5da748e9f37a
17/08/11 03:03:25 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/4c6cef6e-5f7d-44c4-9db1-5da748e9f37a/_tmp_space.db
17/08/11 03:03:26 INFO hive.HiveContext: default warehouse location is /user/hive/warehouse
17/08/11 03:03:26 INFO hive.HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/08/11 03:03:26 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:03:26 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:03:26 INFO hive.metastore: Trying to connect to metastore with URI thrift://sandbox:9083
17/08/11 03:03:26 INFO hive.metastore: Connected to metastore.
17/08/11 03:03:26 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/8b579d0e-67db-4aba-bfd6-8d788559fbd4
17/08/11 03:03:26 INFO session.SessionState: Created local directory: /tmp/root/8b579d0e-67db-4aba-bfd6-8d788559fbd4
17/08/11 03:03:26 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/8b579d0e-67db-4aba-bfd6-8d788559fbd4/_tmp_space.db
17/08/11 03:03:26 INFO persist.LoggerPersist: profileEnum_1502420581895_White start
17/08/11 03:03:27 INFO avro.AvroRelation: Listing hdfs://sandbox:9000/griffin/data/enum-profiling-sample/test_src.avro on driver
17/08/11 03:03:27 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 61.9 KB, free 61.9 KB)
17/08/11 03:03:27 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.6 KB, free 81.5 KB)
17/08/11 03:03:27 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.2:46192 (size: 19.6 KB, free: 511.1 MB)
17/08/11 03:03:27 INFO spark.SparkContext: Created broadcast 0 from flatMap at AvroDataConnector.scala:66
17/08/11 03:03:27 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 212.9 KB, free 294.3 KB)
17/08/11 03:03:27 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.6 KB, free 313.9 KB)
17/08/11 03:03:27 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.2:46192 (size: 19.6 KB, free: 511.1 MB)
17/08/11 03:03:27 INFO spark.SparkContext: Created broadcast 1 from hadoopFile at AvroRelation.scala:121
17/08/11 03:03:28 INFO mapred.FileInputFormat: Total input paths to process : 1
17/08/11 03:03:28 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:42
17/08/11 03:03:28 INFO scheduler.DAGScheduler: Got job 0 (count at ProfileCore.scala:42) with 2 output partitions
17/08/11 03:03:28 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (count at ProfileCore.scala:42)
17/08/11 03:03:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:28 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:28 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36), which has no missing parents
17/08/11 03:03:28 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.3 KB, free 327.2 KB)
17/08/11 03:03:28 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KB, free 333.3 KB)
17/08/11 03:03:28 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.2:46192 (size: 6.2 KB, free: 511.1 MB)
17/08/11 03:03:28 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:28 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36)
17/08/11 03:03:28 INFO cluster.YarnScheduler: Adding task set 0.0 with 2 tasks
17/08/11 03:03:28 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:29 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox:38392 (size: 6.2 KB, free: 511.1 MB)
17/08/11 03:03:31 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox:38392 (size: 19.6 KB, free: 511.1 MB)
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4797 ms on sandbox (1/2)
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 214 ms on sandbox (2/2)
17/08/11 03:03:33 INFO scheduler.DAGScheduler: ResultStage 0 (count at ProfileCore.scala:42) finished in 4.969 s
17/08/11 03:03:33 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Job 0 finished: count at ProfileCore.scala:42, took 5.090666 s
17/08/11 03:03:33 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:44
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Got job 1 (count at ProfileCore.scala:44) with 2 output partitions
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (count at ProfileCore.scala:44)
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43), which has no missing parents
17/08/11 03:03:33 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.6 KB, free 346.9 KB)
17/08/11 03:03:33 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.3 KB, free 353.2 KB)
17/08/11 03:03:33 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.2:46192 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:03:33 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43)
17/08/11 03:03:33 INFO cluster.YarnScheduler: Adding task set 1.0 with 2 tasks
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:33 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox:38392 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 186 ms on sandbox (1/2)
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 137 ms on sandbox (2/2)
17/08/11 03:03:33 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/08/11 03:03:33 INFO scheduler.DAGScheduler: ResultStage 1 (count at ProfileCore.scala:44) finished in 0.317 s
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Job 1 finished: count at ProfileCore.scala:44, took 0.329967 s
17/08/11 03:03:33 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:46
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Got job 2 (count at ProfileCore.scala:46) with 2 output partitions
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (count at ProfileCore.scala:46)
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45), which has no missing parents
17/08/11 03:03:33 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.6 KB, free 366.8 KB)
17/08/11 03:03:33 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.3 KB, free 373.1 KB)
17/08/11 03:03:33 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.2:46192 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:03:33 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45)
17/08/11 03:03:33 INFO cluster.YarnScheduler: Adding task set 2.0 with 2 tasks
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:33 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on sandbox:38392 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 153 ms on sandbox (1/2)
17/08/11 03:03:33 INFO scheduler.DAGScheduler: ResultStage 2 (count at ProfileCore.scala:46) finished in 0.283 s
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 132 ms on sandbox (2/2)
17/08/11 03:03:33 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Job 2 finished: count at ProfileCore.scala:46, took 0.293951 s
17/08/11 03:03:33 INFO persist.LoggerPersist: 1502420613883: calculation using time: 7080 ms
17/08/11 03:03:33 INFO persist.LoggerPersist: profileEnum_1502420581895_White result: 
match percentage: 85.42735173981143
total count: 32561
miss count: 4745, match count: 27816
17/08/11 03:03:33 INFO persist.HttpPersist: post to http://10.149.247.156:49200/griffin/accuracy response status: 201
17/08/11 03:03:33 INFO persist.LoggerPersist: profileEnum_1502420581895_White match records: 
17/08/11 03:03:33 INFO spark.SparkContext: Starting job: count at LoggerPersist.scala:65
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Got job 3 (count at LoggerPersist.scala:65) with 2 output partitions
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (count at LoggerPersist.scala:65)
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:03:33 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.0 KB, free 387.1 KB)
17/08/11 03:03:33 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 393.5 KB)
17/08/11 03:03:33 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.2:46192 (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:03:33 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:33 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:03:33 INFO cluster.YarnScheduler: Adding task set 3.0 with 2 tasks
17/08/11 03:03:33 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:33 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on sandbox:38392 (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:03:34 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:34 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 209 ms on sandbox (1/2)
17/08/11 03:03:34 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 153 ms on sandbox (2/2)
17/08/11 03:03:34 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/08/11 03:03:34 INFO scheduler.DAGScheduler: ResultStage 3 (count at LoggerPersist.scala:65) finished in 0.360 s
17/08/11 03:03:34 INFO scheduler.DAGScheduler: Job 3 finished: count at LoggerPersist.scala:65, took 0.372943 s
17/08/11 03:03:34 INFO spark.SparkContext: Starting job: take at LoggerPersist.scala:68
17/08/11 03:03:34 INFO scheduler.DAGScheduler: Got job 4 (take at LoggerPersist.scala:68) with 1 output partitions
17/08/11 03:03:34 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (take at LoggerPersist.scala:68)
17/08/11 03:03:34 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:34 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:34 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:03:34 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.2 KB, free 407.7 KB)
17/08/11 03:03:34 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KB, free 414.1 KB)
17/08/11 03:03:34 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.2:46192 (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:03:34 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:34 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:03:34 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks
17/08/11 03:03:34 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:34 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on sandbox:38392 (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:03:34 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 56 ms on sandbox (1/1)
17/08/11 03:03:34 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/08/11 03:03:34 INFO scheduler.DAGScheduler: ResultStage 4 (take at LoggerPersist.scala:68) finished in 0.056 s
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
Map($source['race'] -> White)
17/08/11 03:03:34 INFO scheduler.DAGScheduler: Job 4 finished: take at LoggerPersist.scala:68, took 0.070038 s
17/08/11 03:03:34 INFO persist.LoggerPersist: 1502420614425: persist using time: 542 ms
17/08/11 03:03:34 INFO persist.LoggerPersist: profileEnum_1502420581895_White finish
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/execution/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/execution,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
17/08/11 03:03:34 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
17/08/11 03:03:34 INFO ui.SparkUI: Stopped Spark web UI at http://172.17.0.2:4040
17/08/11 03:03:34 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
17/08/11 03:03:34 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
17/08/11 03:03:34 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
17/08/11 03:03:34 INFO cluster.YarnClientSchedulerBackend: Stopped
17/08/11 03:03:34 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/08/11 03:03:34 INFO storage.MemoryStore: MemoryStore cleared
17/08/11 03:03:34 INFO storage.BlockManager: BlockManager stopped
17/08/11 03:03:34 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/08/11 03:03:34 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/08/11 03:03:34 INFO spark.SparkContext: Successfully stopped SparkContext
17/08/11 03:03:34 INFO batch.Application$: calculation finished
17/08/11 03:03:34 INFO batch.Application$: [Ljava.lang.String;@1bd6bfb0
17/08/11 03:03:34 INFO batch.Application$: env.json
17/08/11 03:03:34 INFO batch.Application$: {"name":"profileEnum_1502420614562_Black","type":"profile","source":{"type":"avro","version":"1.7","config":{"file.name":"hdfs:///griffin/data/enum-profiling-sample/test_src.avro"}},"evaluateRule":{"sampleRatio":1,"rules":"$source.race == 'Black'"}}
17/08/11 03:03:34 INFO batch.Application$: params validation pass
17/08/11 03:03:34 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/08/11 03:03:34 INFO spark.SparkContext: Running Spark version 1.6.0
17/08/11 03:03:34 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/08/11 03:03:34 WARN spark.SparkConf: 
SPARK_JAVA_OPTS was detected (set to '-Dspark.driver.port=53411').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
17/08/11 03:03:34 WARN spark.SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:03:34 WARN spark.SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:03:34 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:03:34 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:03:34 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:03:34 INFO util.Utils: Successfully started service 'sparkDriver' on port 53411.
17/08/11 03:03:34 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/08/11 03:03:34 INFO Remoting: Starting remoting
17/08/11 03:03:34 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/08/11 03:03:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.17.0.2:53412]
17/08/11 03:03:34 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 53412.
17/08/11 03:03:34 INFO spark.SparkEnv: Registering MapOutputTracker
17/08/11 03:03:34 INFO spark.SparkEnv: Registering BlockManagerMaster
17/08/11 03:03:34 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-538aef8b-5be4-4921-862e-fd03542120aa
17/08/11 03:03:34 INFO storage.MemoryStore: MemoryStore started with capacity 497.6 MB
17/08/11 03:03:34 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/08/11 03:03:34 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:03:34 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
17/08/11 03:03:34 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/08/11 03:03:34 INFO ui.SparkUI: Started SparkUI at http://172.17.0.2:4040
17/08/11 03:03:34 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-d870316b-dfd3-4ee7-956f-5e697d6eebc0
17/08/11 03:03:34 INFO spark.HttpServer: Starting HTTP Server
17/08/11 03:03:34 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:03:34 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33537
17/08/11 03:03:34 INFO util.Utils: Successfully started service 'HTTP file server' on port 33537.
17/08/11 03:03:35 INFO spark.SparkContext: Added JAR file:/root/griffin-sample/enum-profiling-sample/sample/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar at http://172.17.0.2:33537/jars/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1502420615213
17/08/11 03:03:35 INFO client.RMProxy: Connecting to ResourceManager at sandbox/172.17.0.2:8032
17/08/11 03:03:35 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
17/08/11 03:03:35 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
17/08/11 03:03:35 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/08/11 03:03:35 INFO yarn.Client: Setting up container launch context for our AM
17/08/11 03:03:35 INFO yarn.Client: Setting up the launch environment for our AM container
17/08/11 03:03:35 INFO yarn.Client: Preparing resources for our AM container
17/08/11 03:03:35 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs:/home/spark_lib/spark-assembly-1.6.0-hadoop2.6.0.jar
17/08/11 03:03:35 INFO yarn.Client: Uploading resource file:/apache/spark/conf/hive-site.xml -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0060/hive-site.xml
17/08/11 03:03:35 INFO yarn.Client: Uploading resource file:/tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/__spark_conf__2759501171084271319.zip -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0060/__spark_conf__2759501171084271319.zip
17/08/11 03:03:35 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:03:35 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:03:35 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:03:35 INFO yarn.Client: Submitting application 60 to ResourceManager
17/08/11 03:03:35 INFO impl.YarnClientImpl: Submitted application application_1500434006041_0060
17/08/11 03:03:36 INFO yarn.Client: Application report for application_1500434006041_0060 (state: ACCEPTED)
17/08/11 03:03:36 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1502420615339
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0060/
	 user: root
17/08/11 03:03:37 INFO yarn.Client: Application report for application_1500434006041_0060 (state: ACCEPTED)
17/08/11 03:03:38 INFO yarn.Client: Application report for application_1500434006041_0060 (state: ACCEPTED)
17/08/11 03:03:39 INFO yarn.Client: Application report for application_1500434006041_0060 (state: ACCEPTED)
17/08/11 03:03:40 INFO yarn.Client: Application report for application_1500434006041_0060 (state: ACCEPTED)
17/08/11 03:03:41 INFO yarn.Client: Application report for application_1500434006041_0060 (state: ACCEPTED)
17/08/11 03:03:41 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/08/11 03:03:42 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> sandbox, PROXY_URI_BASES -> http://sandbox:8088/proxy/application_1500434006041_0060), /proxy/application_1500434006041_0060
17/08/11 03:03:42 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/08/11 03:03:42 INFO yarn.Client: Application report for application_1500434006041_0060 (state: RUNNING)
17/08/11 03:03:42 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.17.0.2
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1502420615339
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0060/
	 user: root
17/08/11 03:03:42 INFO cluster.YarnClientSchedulerBackend: Application application_1500434006041_0060 has started running.
17/08/11 03:03:42 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35775.
17/08/11 03:03:42 INFO netty.NettyBlockTransferService: Server created on 35775
17/08/11 03:03:42 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/08/11 03:03:42 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.17.0.2:35775 with 497.6 MB RAM, BlockManagerId(driver, 172.17.0.2, 35775)
17/08/11 03:03:42 INFO storage.BlockManagerMaster: Registered BlockManager
17/08/11 03:03:48 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sandbox:41745) with ID 1
17/08/11 03:03:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager sandbox:54351 with 511.1 MB RAM, BlockManagerId(1, sandbox, 54351)
17/08/11 03:03:48 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/08/11 03:03:48 INFO hive.HiveContext: Initializing execution hive, version 1.2.1
17/08/11 03:03:48 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:03:48 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:03:48 INFO hive.metastore: Mestastore configuration hive.metastore.warehouse.dir changed from file:/tmp/spark-331c69ca-6843-4ba3-8560-d0a1a4518de9/metastore to file:/tmp/spark-9889b9d1-d8d9-4076-b442-1b85d5fdf0dc/metastore
17/08/11 03:03:48 INFO hive.metastore: Mestastore configuration javax.jdo.option.ConnectionURL changed from jdbc:derby:;databaseName=/tmp/spark-331c69ca-6843-4ba3-8560-d0a1a4518de9/metastore;create=true to jdbc:derby:;databaseName=/tmp/spark-9889b9d1-d8d9-4076-b442-1b85d5fdf0dc/metastore;create=true
17/08/11 03:03:48 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
17/08/11 03:03:48 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=Shutting down the object store...	
17/08/11 03:03:48 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
17/08/11 03:03:48 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
17/08/11 03:03:48 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/08/11 03:03:48 INFO metastore.ObjectStore: ObjectStore, initialize called
17/08/11 03:03:48 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/08/11 03:03:48 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/08/11 03:03:49 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/08/11 03:03:49 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:49 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:50 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:50 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:03:50 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/08/11 03:03:50 INFO metastore.ObjectStore: Initialized ObjectStore
17/08/11 03:03:50 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
17/08/11 03:03:50 INFO metastore.HiveMetaStore: Added admin role in metastore
17/08/11 03:03:50 INFO metastore.HiveMetaStore: Added public role in metastore
17/08/11 03:03:50 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
17/08/11 03:03:50 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/30ff4953-47e9-4cdb-adce-c84b209a0820
17/08/11 03:03:50 INFO session.SessionState: Created local directory: /tmp/root/30ff4953-47e9-4cdb-adce-c84b209a0820
17/08/11 03:03:50 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/30ff4953-47e9-4cdb-adce-c84b209a0820/_tmp_space.db
17/08/11 03:03:50 INFO hive.HiveContext: default warehouse location is /user/hive/warehouse
17/08/11 03:03:50 INFO hive.HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/08/11 03:03:50 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:03:50 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:03:51 INFO hive.metastore: Trying to connect to metastore with URI thrift://sandbox:9083
17/08/11 03:03:51 INFO hive.metastore: Connected to metastore.
17/08/11 03:03:51 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/81931882-7d67-4c90-9289-16dcec40e7c0
17/08/11 03:03:51 INFO session.SessionState: Created local directory: /tmp/root/81931882-7d67-4c90-9289-16dcec40e7c0
17/08/11 03:03:51 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/81931882-7d67-4c90-9289-16dcec40e7c0/_tmp_space.db
17/08/11 03:03:51 INFO persist.LoggerPersist: profileEnum_1502420614562_Black start
17/08/11 03:03:51 INFO avro.AvroRelation: Listing hdfs://sandbox:9000/griffin/data/enum-profiling-sample/test_src.avro on driver
17/08/11 03:03:51 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 212.9 KB, free 212.9 KB)
17/08/11 03:03:51 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.6 KB, free 232.5 KB)
17/08/11 03:03:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.2:35775 (size: 19.6 KB, free: 497.6 MB)
17/08/11 03:03:51 INFO spark.SparkContext: Created broadcast 0 from flatMap at AvroDataConnector.scala:66
17/08/11 03:03:51 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 212.9 KB, free 445.4 KB)
17/08/11 03:03:51 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.6 KB, free 464.9 KB)
17/08/11 03:03:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.2:35775 (size: 19.6 KB, free: 497.6 MB)
17/08/11 03:03:51 INFO spark.SparkContext: Created broadcast 1 from hadoopFile at AvroRelation.scala:121
17/08/11 03:03:51 INFO mapred.FileInputFormat: Total input paths to process : 1
17/08/11 03:03:51 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:42
17/08/11 03:03:51 INFO scheduler.DAGScheduler: Got job 0 (count at ProfileCore.scala:42) with 2 output partitions
17/08/11 03:03:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (count at ProfileCore.scala:42)
17/08/11 03:03:51 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:51 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36), which has no missing parents
17/08/11 03:03:51 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.3 KB, free 478.2 KB)
17/08/11 03:03:51 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KB, free 484.4 KB)
17/08/11 03:03:51 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.2:35775 (size: 6.2 KB, free: 497.6 MB)
17/08/11 03:03:51 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:51 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36)
17/08/11 03:03:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 2 tasks
17/08/11 03:03:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:52 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox:54351 (size: 6.2 KB, free: 511.1 MB)
17/08/11 03:03:54 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox:54351 (size: 19.6 KB, free: 511.1 MB)
17/08/11 03:03:55 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4395 ms on sandbox (1/2)
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 218 ms on sandbox (2/2)
17/08/11 03:03:56 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/08/11 03:03:56 INFO scheduler.DAGScheduler: ResultStage 0 (count at ProfileCore.scala:42) finished in 4.599 s
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Job 0 finished: count at ProfileCore.scala:42, took 4.621383 s
17/08/11 03:03:56 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:44
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Got job 1 (count at ProfileCore.scala:44) with 2 output partitions
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (count at ProfileCore.scala:44)
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43), which has no missing parents
17/08/11 03:03:56 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.6 KB, free 498.0 KB)
17/08/11 03:03:56 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.3 KB, free 504.3 KB)
17/08/11 03:03:56 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.2:35775 (size: 6.3 KB, free: 497.6 MB)
17/08/11 03:03:56 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43)
17/08/11 03:03:56 INFO cluster.YarnScheduler: Adding task set 1.0 with 2 tasks
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:56 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox:54351 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 178 ms on sandbox (1/2)
17/08/11 03:03:56 INFO scheduler.DAGScheduler: ResultStage 1 (count at ProfileCore.scala:44) finished in 0.326 s
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 152 ms on sandbox (2/2)
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Job 1 finished: count at ProfileCore.scala:44, took 0.337246 s
17/08/11 03:03:56 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/08/11 03:03:56 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:46
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Got job 2 (count at ProfileCore.scala:46) with 2 output partitions
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (count at ProfileCore.scala:46)
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45), which has no missing parents
17/08/11 03:03:56 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.6 KB, free 517.9 KB)
17/08/11 03:03:56 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.3 KB, free 524.2 KB)
17/08/11 03:03:56 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.2:35775 (size: 6.3 KB, free: 497.6 MB)
17/08/11 03:03:56 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45)
17/08/11 03:03:56 INFO cluster.YarnScheduler: Adding task set 2.0 with 2 tasks
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:56 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on sandbox:54351 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 160 ms on sandbox (1/2)
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 134 ms on sandbox (2/2)
17/08/11 03:03:56 INFO scheduler.DAGScheduler: ResultStage 2 (count at ProfileCore.scala:46) finished in 0.291 s
17/08/11 03:03:56 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Job 2 finished: count at ProfileCore.scala:46, took 0.303147 s
17/08/11 03:03:56 INFO persist.LoggerPersist: 1502420636715: calculation using time: 5470 ms
17/08/11 03:03:56 INFO persist.LoggerPersist: profileEnum_1502420614562_Black result: 
match percentage: 9.59429992936335
total count: 32561
miss count: 29437, match count: 3124
17/08/11 03:03:56 INFO persist.HttpPersist: post to http://10.149.247.156:49200/griffin/accuracy response status: 201
17/08/11 03:03:56 INFO persist.LoggerPersist: profileEnum_1502420614562_Black match records: 
17/08/11 03:03:56 INFO spark.SparkContext: Starting job: count at LoggerPersist.scala:65
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Got job 3 (count at LoggerPersist.scala:65) with 2 output partitions
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (count at LoggerPersist.scala:65)
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:03:56 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.0 KB, free 538.2 KB)
17/08/11 03:03:56 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 544.6 KB)
17/08/11 03:03:56 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.2:35775 (size: 6.4 KB, free: 497.6 MB)
17/08/11 03:03:56 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:56 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:03:56 INFO cluster.YarnScheduler: Adding task set 3.0 with 2 tasks
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:56 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on sandbox:54351 (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:56 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 171 ms on sandbox (1/2)
17/08/11 03:03:57 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 137 ms on sandbox (2/2)
17/08/11 03:03:57 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/08/11 03:03:57 INFO scheduler.DAGScheduler: ResultStage 3 (count at LoggerPersist.scala:65) finished in 0.306 s
17/08/11 03:03:57 INFO scheduler.DAGScheduler: Job 3 finished: count at LoggerPersist.scala:65, took 0.323921 s
17/08/11 03:03:57 INFO spark.SparkContext: Starting job: take at LoggerPersist.scala:68
17/08/11 03:03:57 INFO scheduler.DAGScheduler: Got job 4 (take at LoggerPersist.scala:68) with 1 output partitions
17/08/11 03:03:57 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (take at LoggerPersist.scala:68)
17/08/11 03:03:57 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:03:57 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:03:57 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:03:57 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.2 KB, free 558.8 KB)
17/08/11 03:03:57 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.5 KB, free 565.2 KB)
17/08/11 03:03:57 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.2:35775 (size: 6.5 KB, free: 497.6 MB)
17/08/11 03:03:57 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
17/08/11 03:03:57 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:03:57 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks
17/08/11 03:03:57 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:03:57 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on sandbox:54351 (size: 6.5 KB, free: 511.1 MB)
17/08/11 03:03:57 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 44 ms on sandbox (1/1)
17/08/11 03:03:57 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/08/11 03:03:57 INFO scheduler.DAGScheduler: ResultStage 4 (take at LoggerPersist.scala:68) finished in 0.048 s
17/08/11 03:03:57 INFO scheduler.DAGScheduler: Job 4 finished: take at LoggerPersist.scala:68, took 0.060666 s
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
Map($source['race'] -> Black)
17/08/11 03:03:57 INFO persist.LoggerPersist: 1502420637133: persist using time: 418 ms
17/08/11 03:03:57 INFO persist.LoggerPersist: profileEnum_1502420614562_Black finish
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL1/execution/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL1/execution,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL1/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL1,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
17/08/11 03:03:57 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
17/08/11 03:03:57 INFO ui.SparkUI: Stopped Spark web UI at http://172.17.0.2:4040
17/08/11 03:03:57 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
17/08/11 03:03:57 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
17/08/11 03:03:57 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
17/08/11 03:03:57 INFO cluster.YarnClientSchedulerBackend: Stopped
17/08/11 03:03:57 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/08/11 03:03:57 INFO storage.MemoryStore: MemoryStore cleared
17/08/11 03:03:57 INFO storage.BlockManager: BlockManager stopped
17/08/11 03:03:57 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/08/11 03:03:57 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/08/11 03:03:57 INFO spark.SparkContext: Successfully stopped SparkContext
17/08/11 03:03:57 INFO batch.Application$: calculation finished
17/08/11 03:03:57 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/08/11 03:03:57 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/08/11 03:03:57 INFO batch.Application$: [Ljava.lang.String;@6ca6cc1c
17/08/11 03:03:57 INFO batch.Application$: env.json
17/08/11 03:03:57 INFO batch.Application$: {"name":"profileEnum_1502420637237_Asian-Pac-Islander","type":"profile","source":{"type":"avro","version":"1.7","config":{"file.name":"hdfs:///griffin/data/enum-profiling-sample/test_src.avro"}},"evaluateRule":{"sampleRatio":1,"rules":"$source.race == 'Asian-Pac-Islander'"}}
17/08/11 03:03:57 INFO batch.Application$: params validation pass
17/08/11 03:03:57 INFO spark.SparkContext: Running Spark version 1.6.0
17/08/11 03:03:57 WARN spark.SparkConf: 
SPARK_JAVA_OPTS was detected (set to '-Dspark.driver.port=53411').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
17/08/11 03:03:57 WARN spark.SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:03:57 WARN spark.SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:03:57 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/08/11 03:03:57 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:03:57 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:03:57 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:03:57 INFO util.Utils: Successfully started service 'sparkDriver' on port 53411.
17/08/11 03:03:57 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/08/11 03:03:57 INFO Remoting: Starting remoting
17/08/11 03:03:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.17.0.2:53412]
17/08/11 03:03:57 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 53412.
17/08/11 03:03:57 INFO spark.SparkEnv: Registering MapOutputTracker
17/08/11 03:03:57 INFO spark.SparkEnv: Registering BlockManagerMaster
17/08/11 03:03:57 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-1664067d-40ff-40b0-a81b-9b2ceb2ac9a3
17/08/11 03:03:57 INFO storage.MemoryStore: MemoryStore started with capacity 463.9 MB
17/08/11 03:03:57 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/08/11 03:03:57 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:03:57 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
17/08/11 03:03:57 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/08/11 03:03:57 INFO ui.SparkUI: Started SparkUI at http://172.17.0.2:4040
17/08/11 03:03:57 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-7946d297-5bce-4233-aedb-76c843004e75
17/08/11 03:03:57 INFO spark.HttpServer: Starting HTTP Server
17/08/11 03:03:57 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:03:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43579
17/08/11 03:03:57 INFO util.Utils: Successfully started service 'HTTP file server' on port 43579.
17/08/11 03:03:57 INFO spark.SparkContext: Added JAR file:/root/griffin-sample/enum-profiling-sample/sample/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar at http://172.17.0.2:43579/jars/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1502420637685
17/08/11 03:03:57 INFO client.RMProxy: Connecting to ResourceManager at sandbox/172.17.0.2:8032
17/08/11 03:03:57 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
17/08/11 03:03:57 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
17/08/11 03:03:57 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/08/11 03:03:57 INFO yarn.Client: Setting up container launch context for our AM
17/08/11 03:03:57 INFO yarn.Client: Setting up the launch environment for our AM container
17/08/11 03:03:57 INFO yarn.Client: Preparing resources for our AM container
17/08/11 03:03:57 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs:/home/spark_lib/spark-assembly-1.6.0-hadoop2.6.0.jar
17/08/11 03:03:57 INFO yarn.Client: Uploading resource file:/apache/spark/conf/hive-site.xml -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0061/hive-site.xml
17/08/11 03:03:57 INFO yarn.Client: Uploading resource file:/tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/__spark_conf__2486647420007001519.zip -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0061/__spark_conf__2486647420007001519.zip
17/08/11 03:03:57 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:03:57 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:03:57 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:03:57 INFO yarn.Client: Submitting application 61 to ResourceManager
17/08/11 03:03:57 INFO impl.YarnClientImpl: Submitted application application_1500434006041_0061
17/08/11 03:03:58 INFO yarn.Client: Application report for application_1500434006041_0061 (state: ACCEPTED)
17/08/11 03:03:58 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1502420637843
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0061/
	 user: root
17/08/11 03:03:59 INFO yarn.Client: Application report for application_1500434006041_0061 (state: ACCEPTED)
17/08/11 03:04:00 INFO yarn.Client: Application report for application_1500434006041_0061 (state: ACCEPTED)
17/08/11 03:04:01 INFO yarn.Client: Application report for application_1500434006041_0061 (state: ACCEPTED)
17/08/11 03:04:02 INFO yarn.Client: Application report for application_1500434006041_0061 (state: ACCEPTED)
17/08/11 03:04:03 INFO yarn.Client: Application report for application_1500434006041_0061 (state: ACCEPTED)
17/08/11 03:04:04 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/08/11 03:04:04 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> sandbox, PROXY_URI_BASES -> http://sandbox:8088/proxy/application_1500434006041_0061), /proxy/application_1500434006041_0061
17/08/11 03:04:04 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/08/11 03:04:04 INFO yarn.Client: Application report for application_1500434006041_0061 (state: ACCEPTED)
17/08/11 03:04:05 INFO yarn.Client: Application report for application_1500434006041_0061 (state: RUNNING)
17/08/11 03:04:05 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.17.0.2
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1502420637843
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0061/
	 user: root
17/08/11 03:04:05 INFO cluster.YarnClientSchedulerBackend: Application application_1500434006041_0061 has started running.
17/08/11 03:04:05 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37668.
17/08/11 03:04:05 INFO netty.NettyBlockTransferService: Server created on 37668
17/08/11 03:04:05 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/08/11 03:04:05 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.17.0.2:37668 with 463.9 MB RAM, BlockManagerId(driver, 172.17.0.2, 37668)
17/08/11 03:04:05 INFO storage.BlockManagerMaster: Registered BlockManager
17/08/11 03:04:12 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sandbox:41796) with ID 1
17/08/11 03:04:12 INFO storage.BlockManagerMasterEndpoint: Registering block manager sandbox:48412 with 511.1 MB RAM, BlockManagerId(1, sandbox, 48412)
17/08/11 03:04:12 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/08/11 03:04:12 INFO hive.HiveContext: Initializing execution hive, version 1.2.1
17/08/11 03:04:12 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:04:12 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:04:13 INFO hive.metastore: Mestastore configuration hive.metastore.warehouse.dir changed from file:/tmp/spark-9889b9d1-d8d9-4076-b442-1b85d5fdf0dc/metastore to file:/tmp/spark-6069def1-f7dc-4ae0-b23d-bf17aa97a81e/metastore
17/08/11 03:04:13 INFO hive.metastore: Mestastore configuration javax.jdo.option.ConnectionURL changed from jdbc:derby:;databaseName=/tmp/spark-9889b9d1-d8d9-4076-b442-1b85d5fdf0dc/metastore;create=true to jdbc:derby:;databaseName=/tmp/spark-6069def1-f7dc-4ae0-b23d-bf17aa97a81e/metastore;create=true
17/08/11 03:04:13 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
17/08/11 03:04:13 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=Shutting down the object store...	
17/08/11 03:04:13 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
17/08/11 03:04:13 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
17/08/11 03:04:13 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/08/11 03:04:13 INFO metastore.ObjectStore: ObjectStore, initialize called
17/08/11 03:04:13 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/08/11 03:04:13 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/08/11 03:04:13 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/08/11 03:04:13 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:13 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:14 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:14 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:14 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/08/11 03:04:14 INFO metastore.ObjectStore: Initialized ObjectStore
17/08/11 03:04:14 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
17/08/11 03:04:14 INFO metastore.HiveMetaStore: Added admin role in metastore
17/08/11 03:04:14 INFO metastore.HiveMetaStore: Added public role in metastore
17/08/11 03:04:15 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
17/08/11 03:04:15 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/d661aaf8-a3ea-49df-9584-7f1cc84f4c9c
17/08/11 03:04:15 INFO session.SessionState: Created local directory: /tmp/root/d661aaf8-a3ea-49df-9584-7f1cc84f4c9c
17/08/11 03:04:15 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/d661aaf8-a3ea-49df-9584-7f1cc84f4c9c/_tmp_space.db
17/08/11 03:04:15 INFO hive.HiveContext: default warehouse location is /user/hive/warehouse
17/08/11 03:04:15 INFO hive.HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/08/11 03:04:15 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:04:15 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:04:15 INFO hive.metastore: Trying to connect to metastore with URI thrift://sandbox:9083
17/08/11 03:04:15 INFO hive.metastore: Connected to metastore.
17/08/11 03:04:15 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/7df68921-c600-4823-9e6b-18c398a31e66
17/08/11 03:04:15 INFO session.SessionState: Created local directory: /tmp/root/7df68921-c600-4823-9e6b-18c398a31e66
17/08/11 03:04:15 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/7df68921-c600-4823-9e6b-18c398a31e66/_tmp_space.db
17/08/11 03:04:15 INFO persist.LoggerPersist: profileEnum_1502420637237_Asian-Pac-Islander start
17/08/11 03:04:15 INFO avro.AvroRelation: Listing hdfs://sandbox:9000/griffin/data/enum-profiling-sample/test_src.avro on driver
17/08/11 03:04:15 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 212.9 KB, free 212.9 KB)
17/08/11 03:04:15 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.6 KB, free 232.5 KB)
17/08/11 03:04:15 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.2:37668 (size: 19.6 KB, free: 463.9 MB)
17/08/11 03:04:15 INFO spark.SparkContext: Created broadcast 0 from flatMap at AvroDataConnector.scala:66
17/08/11 03:04:15 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 212.9 KB, free 445.4 KB)
17/08/11 03:04:15 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.6 KB, free 464.9 KB)
17/08/11 03:04:15 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.2:37668 (size: 19.6 KB, free: 463.8 MB)
17/08/11 03:04:15 INFO spark.SparkContext: Created broadcast 1 from hadoopFile at AvroRelation.scala:121
17/08/11 03:04:15 INFO mapred.FileInputFormat: Total input paths to process : 1
17/08/11 03:04:15 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:42
17/08/11 03:04:15 INFO scheduler.DAGScheduler: Got job 0 (count at ProfileCore.scala:42) with 2 output partitions
17/08/11 03:04:15 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (count at ProfileCore.scala:42)
17/08/11 03:04:15 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:15 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:15 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36), which has no missing parents
17/08/11 03:04:15 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.3 KB, free 478.3 KB)
17/08/11 03:04:15 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KB, free 484.5 KB)
17/08/11 03:04:15 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.2:37668 (size: 6.2 KB, free: 463.8 MB)
17/08/11 03:04:15 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:15 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36)
17/08/11 03:04:15 INFO cluster.YarnScheduler: Adding task set 0.0 with 2 tasks
17/08/11 03:04:15 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:16 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox:48412 (size: 6.2 KB, free: 511.1 MB)
17/08/11 03:04:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox:48412 (size: 19.6 KB, free: 511.1 MB)
17/08/11 03:04:19 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:19 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3867 ms on sandbox (1/2)
17/08/11 03:04:19 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 216 ms on sandbox (2/2)
17/08/11 03:04:19 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/08/11 03:04:19 INFO scheduler.DAGScheduler: ResultStage 0 (count at ProfileCore.scala:42) finished in 4.075 s
17/08/11 03:04:19 INFO scheduler.DAGScheduler: Job 0 finished: count at ProfileCore.scala:42, took 4.086859 s
17/08/11 03:04:19 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:44
17/08/11 03:04:19 INFO scheduler.DAGScheduler: Got job 1 (count at ProfileCore.scala:44) with 2 output partitions
17/08/11 03:04:19 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (count at ProfileCore.scala:44)
17/08/11 03:04:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:19 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:19 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43), which has no missing parents
17/08/11 03:04:19 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.7 KB, free 498.1 KB)
17/08/11 03:04:19 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.3 KB, free 504.4 KB)
17/08/11 03:04:19 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.2:37668 (size: 6.3 KB, free: 463.8 MB)
17/08/11 03:04:19 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:19 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43)
17/08/11 03:04:19 INFO cluster.YarnScheduler: Adding task set 1.0 with 2 tasks
17/08/11 03:04:19 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:19 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox:48412 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:04:19 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:19 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 176 ms on sandbox (1/2)
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 142 ms on sandbox (2/2)
17/08/11 03:04:20 INFO scheduler.DAGScheduler: ResultStage 1 (count at ProfileCore.scala:44) finished in 0.312 s
17/08/11 03:04:20 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Job 1 finished: count at ProfileCore.scala:44, took 0.325018 s
17/08/11 03:04:20 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:46
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Got job 2 (count at ProfileCore.scala:46) with 2 output partitions
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (count at ProfileCore.scala:46)
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45), which has no missing parents
17/08/11 03:04:20 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.7 KB, free 518.1 KB)
17/08/11 03:04:20 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.3 KB, free 524.4 KB)
17/08/11 03:04:20 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.2:37668 (size: 6.3 KB, free: 463.8 MB)
17/08/11 03:04:20 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45)
17/08/11 03:04:20 INFO cluster.YarnScheduler: Adding task set 2.0 with 2 tasks
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:20 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on sandbox:48412 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 163 ms on sandbox (1/2)
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 138 ms on sandbox (2/2)
17/08/11 03:04:20 INFO scheduler.DAGScheduler: ResultStage 2 (count at ProfileCore.scala:46) finished in 0.296 s
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Job 2 finished: count at ProfileCore.scala:46, took 0.308692 s
17/08/11 03:04:20 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/08/11 03:04:20 INFO persist.LoggerPersist: 1502420660409: calculation using time: 4816 ms
17/08/11 03:04:20 INFO persist.LoggerPersist: profileEnum_1502420637237_Asian-Pac-Islander result: 
match percentage: 3.190933939375326
total count: 32561
miss count: 31522, match count: 1039
17/08/11 03:04:20 INFO persist.HttpPersist: post to http://10.149.247.156:49200/griffin/accuracy response status: 201
17/08/11 03:04:20 INFO persist.LoggerPersist: profileEnum_1502420637237_Asian-Pac-Islander match records: 
17/08/11 03:04:20 INFO spark.SparkContext: Starting job: count at LoggerPersist.scala:65
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Got job 3 (count at LoggerPersist.scala:65) with 2 output partitions
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (count at LoggerPersist.scala:65)
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:04:20 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.1 KB, free 538.5 KB)
17/08/11 03:04:20 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 544.9 KB)
17/08/11 03:04:20 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.2:37668 (size: 6.4 KB, free: 463.8 MB)
17/08/11 03:04:20 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:04:20 INFO cluster.YarnScheduler: Adding task set 3.0 with 2 tasks
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:20 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on sandbox:48412 (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 170 ms on sandbox (1/2)
17/08/11 03:04:20 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 133 ms on sandbox (2/2)
17/08/11 03:04:20 INFO scheduler.DAGScheduler: ResultStage 3 (count at LoggerPersist.scala:65) finished in 0.299 s
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Job 3 finished: count at LoggerPersist.scala:65, took 0.307425 s
17/08/11 03:04:20 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/08/11 03:04:20 INFO spark.SparkContext: Starting job: take at LoggerPersist.scala:68
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Got job 4 (take at LoggerPersist.scala:68) with 1 output partitions
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (take at LoggerPersist.scala:68)
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:20 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:04:20 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.2 KB, free 559.1 KB)
17/08/11 03:04:21 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.5 KB, free 565.6 KB)
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.2:37668 (size: 6.5 KB, free: 463.8 MB)
17/08/11 03:04:21 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:21 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:04:21 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks
17/08/11 03:04:21 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 172.17.0.2:37668 in memory (size: 6.4 KB, free: 463.8 MB)
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on sandbox:48412 (size: 6.5 KB, free: 511.1 MB)
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on sandbox:48412 in memory (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:04:21 INFO spark.ContextCleaner: Cleaned accumulator 14
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 172.17.0.2:37668 in memory (size: 6.3 KB, free: 463.8 MB)
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on sandbox:48412 in memory (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:04:21 INFO spark.ContextCleaner: Cleaned accumulator 13
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 172.17.0.2:37668 in memory (size: 6.3 KB, free: 463.8 MB)
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on sandbox:48412 in memory (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:04:21 INFO spark.ContextCleaner: Cleaned accumulator 12
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 172.17.0.2:37668 in memory (size: 6.2 KB, free: 463.8 MB)
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on sandbox:48412 in memory (size: 6.2 KB, free: 511.1 MB)
17/08/11 03:04:21 INFO spark.ContextCleaner: Cleaned accumulator 11
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
17/08/11 03:04:21 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.17.0.2:37668 in memory (size: 19.6 KB, free: 463.8 MB)
17/08/11 03:04:21 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 66 ms on sandbox (1/1)
17/08/11 03:04:21 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/08/11 03:04:21 INFO scheduler.DAGScheduler: ResultStage 4 (take at LoggerPersist.scala:68) finished in 0.066 s
17/08/11 03:04:21 INFO scheduler.DAGScheduler: Job 4 finished: take at LoggerPersist.scala:68, took 0.486952 s
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
Map($source['race'] -> Asian-Pac-Islander)
17/08/11 03:04:21 INFO persist.LoggerPersist: 1502420661231: persist using time: 822 ms
17/08/11 03:04:21 INFO persist.LoggerPersist: profileEnum_1502420637237_Asian-Pac-Islander finish
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL2/execution/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL2/execution,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL2/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL2,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
17/08/11 03:04:21 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
17/08/11 03:04:21 INFO ui.SparkUI: Stopped Spark web UI at http://172.17.0.2:4040
17/08/11 03:04:21 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
17/08/11 03:04:21 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
17/08/11 03:04:21 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
17/08/11 03:04:21 INFO cluster.YarnClientSchedulerBackend: Stopped
17/08/11 03:04:21 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/08/11 03:04:21 INFO storage.MemoryStore: MemoryStore cleared
17/08/11 03:04:21 INFO storage.BlockManager: BlockManager stopped
17/08/11 03:04:21 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/08/11 03:04:21 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/08/11 03:04:21 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/08/11 03:04:21 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/08/11 03:04:21 INFO spark.SparkContext: Successfully stopped SparkContext
17/08/11 03:04:21 INFO batch.Application$: calculation finished
17/08/11 03:04:21 INFO batch.Application$: [Ljava.lang.String;@a555005
17/08/11 03:04:21 INFO batch.Application$: env.json
17/08/11 03:04:21 INFO batch.Application$: {"name":"profileEnum_1502420661332_Amer-Indian-Eskimo","type":"profile","source":{"type":"avro","version":"1.7","config":{"file.name":"hdfs:///griffin/data/enum-profiling-sample/test_src.avro"}},"evaluateRule":{"sampleRatio":1,"rules":"$source.race == 'Amer-Indian-Eskimo'"}}
17/08/11 03:04:21 INFO batch.Application$: params validation pass
17/08/11 03:04:21 INFO spark.SparkContext: Running Spark version 1.6.0
17/08/11 03:04:21 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/08/11 03:04:21 WARN spark.SparkConf: 
SPARK_JAVA_OPTS was detected (set to '-Dspark.driver.port=53411').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
17/08/11 03:04:21 WARN spark.SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:04:21 WARN spark.SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:04:21 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:04:21 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:04:21 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:04:21 INFO util.Utils: Successfully started service 'sparkDriver' on port 53411.
17/08/11 03:04:21 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/08/11 03:04:21 INFO Remoting: Starting remoting
17/08/11 03:04:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.17.0.2:53412]
17/08/11 03:04:21 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 53412.
17/08/11 03:04:21 INFO spark.SparkEnv: Registering MapOutputTracker
17/08/11 03:04:21 INFO spark.SparkEnv: Registering BlockManagerMaster
17/08/11 03:04:21 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-2b6004ca-da1d-46e0-96b5-e9daa951a31f
17/08/11 03:04:21 INFO storage.MemoryStore: MemoryStore started with capacity 457.9 MB
17/08/11 03:04:21 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/08/11 03:04:21 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:04:21 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
17/08/11 03:04:21 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/08/11 03:04:21 INFO ui.SparkUI: Started SparkUI at http://172.17.0.2:4040
17/08/11 03:04:21 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-148a41fb-2309-4e9e-9a4e-d0b85af685f4
17/08/11 03:04:21 INFO spark.HttpServer: Starting HTTP Server
17/08/11 03:04:21 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:04:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54055
17/08/11 03:04:21 INFO util.Utils: Successfully started service 'HTTP file server' on port 54055.
17/08/11 03:04:21 INFO spark.SparkContext: Added JAR file:/root/griffin-sample/enum-profiling-sample/sample/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar at http://172.17.0.2:54055/jars/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1502420661780
17/08/11 03:04:21 INFO client.RMProxy: Connecting to ResourceManager at sandbox/172.17.0.2:8032
17/08/11 03:04:21 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
17/08/11 03:04:21 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
17/08/11 03:04:21 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/08/11 03:04:21 INFO yarn.Client: Setting up container launch context for our AM
17/08/11 03:04:21 INFO yarn.Client: Setting up the launch environment for our AM container
17/08/11 03:04:21 INFO yarn.Client: Preparing resources for our AM container
17/08/11 03:04:21 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs:/home/spark_lib/spark-assembly-1.6.0-hadoop2.6.0.jar
17/08/11 03:04:21 INFO yarn.Client: Uploading resource file:/apache/spark/conf/hive-site.xml -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0062/hive-site.xml
17/08/11 03:04:21 INFO yarn.Client: Uploading resource file:/tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/__spark_conf__9126705185387314749.zip -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0062/__spark_conf__9126705185387314749.zip
17/08/11 03:04:21 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:04:21 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:04:21 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:04:21 INFO yarn.Client: Submitting application 62 to ResourceManager
17/08/11 03:04:22 INFO impl.YarnClientImpl: Submitted application application_1500434006041_0062
17/08/11 03:04:23 INFO yarn.Client: Application report for application_1500434006041_0062 (state: ACCEPTED)
17/08/11 03:04:23 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1502420661910
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0062/
	 user: root
17/08/11 03:04:24 INFO yarn.Client: Application report for application_1500434006041_0062 (state: ACCEPTED)
17/08/11 03:04:25 INFO yarn.Client: Application report for application_1500434006041_0062 (state: ACCEPTED)
17/08/11 03:04:26 INFO yarn.Client: Application report for application_1500434006041_0062 (state: ACCEPTED)
17/08/11 03:04:27 INFO yarn.Client: Application report for application_1500434006041_0062 (state: ACCEPTED)
17/08/11 03:04:28 INFO yarn.Client: Application report for application_1500434006041_0062 (state: ACCEPTED)
17/08/11 03:04:28 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/08/11 03:04:28 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> sandbox, PROXY_URI_BASES -> http://sandbox:8088/proxy/application_1500434006041_0062), /proxy/application_1500434006041_0062
17/08/11 03:04:28 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/08/11 03:04:29 INFO yarn.Client: Application report for application_1500434006041_0062 (state: RUNNING)
17/08/11 03:04:29 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.17.0.2
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1502420661910
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0062/
	 user: root
17/08/11 03:04:29 INFO cluster.YarnClientSchedulerBackend: Application application_1500434006041_0062 has started running.
17/08/11 03:04:29 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57662.
17/08/11 03:04:29 INFO netty.NettyBlockTransferService: Server created on 57662
17/08/11 03:04:29 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/08/11 03:04:29 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.17.0.2:57662 with 457.9 MB RAM, BlockManagerId(driver, 172.17.0.2, 57662)
17/08/11 03:04:29 INFO storage.BlockManagerMaster: Registered BlockManager
17/08/11 03:04:35 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sandbox:41848) with ID 1
17/08/11 03:04:35 INFO storage.BlockManagerMasterEndpoint: Registering block manager sandbox:39818 with 511.1 MB RAM, BlockManagerId(1, sandbox, 39818)
17/08/11 03:04:35 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/08/11 03:04:35 INFO hive.HiveContext: Initializing execution hive, version 1.2.1
17/08/11 03:04:35 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:04:35 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:04:36 INFO hive.metastore: Mestastore configuration hive.metastore.warehouse.dir changed from file:/tmp/spark-6069def1-f7dc-4ae0-b23d-bf17aa97a81e/metastore to file:/tmp/spark-93edef70-8d5b-47dc-a22e-4da7cef8a77a/metastore
17/08/11 03:04:36 INFO hive.metastore: Mestastore configuration javax.jdo.option.ConnectionURL changed from jdbc:derby:;databaseName=/tmp/spark-6069def1-f7dc-4ae0-b23d-bf17aa97a81e/metastore;create=true to jdbc:derby:;databaseName=/tmp/spark-93edef70-8d5b-47dc-a22e-4da7cef8a77a/metastore;create=true
17/08/11 03:04:36 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
17/08/11 03:04:36 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=Shutting down the object store...	
17/08/11 03:04:36 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
17/08/11 03:04:36 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
17/08/11 03:04:36 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/08/11 03:04:36 INFO metastore.ObjectStore: ObjectStore, initialize called
17/08/11 03:04:36 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/08/11 03:04:36 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/08/11 03:04:36 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/08/11 03:04:36 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:36 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:37 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:37 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:37 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/08/11 03:04:37 INFO metastore.ObjectStore: Initialized ObjectStore
17/08/11 03:04:37 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
17/08/11 03:04:37 INFO metastore.HiveMetaStore: Added admin role in metastore
17/08/11 03:04:37 INFO metastore.HiveMetaStore: Added public role in metastore
17/08/11 03:04:38 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
17/08/11 03:04:38 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/9ce20e02-53c7-4c09-8277-f2ab688c4e58
17/08/11 03:04:38 INFO session.SessionState: Created local directory: /tmp/root/9ce20e02-53c7-4c09-8277-f2ab688c4e58
17/08/11 03:04:38 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/9ce20e02-53c7-4c09-8277-f2ab688c4e58/_tmp_space.db
17/08/11 03:04:38 INFO hive.HiveContext: default warehouse location is /user/hive/warehouse
17/08/11 03:04:38 INFO hive.HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/08/11 03:04:38 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:04:38 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:04:38 INFO hive.metastore: Trying to connect to metastore with URI thrift://sandbox:9083
17/08/11 03:04:38 INFO hive.metastore: Connected to metastore.
17/08/11 03:04:38 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/fc0bf96c-e84d-4159-9dd1-269ab00215dd
17/08/11 03:04:38 INFO session.SessionState: Created local directory: /tmp/root/fc0bf96c-e84d-4159-9dd1-269ab00215dd
17/08/11 03:04:38 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/fc0bf96c-e84d-4159-9dd1-269ab00215dd/_tmp_space.db
17/08/11 03:04:38 INFO persist.LoggerPersist: profileEnum_1502420661332_Amer-Indian-Eskimo start
17/08/11 03:04:38 INFO avro.AvroRelation: Listing hdfs://sandbox:9000/griffin/data/enum-profiling-sample/test_src.avro on driver
17/08/11 03:04:38 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 212.9 KB, free 212.9 KB)
17/08/11 03:04:38 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.6 KB, free 232.5 KB)
17/08/11 03:04:38 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.2:57662 (size: 19.6 KB, free: 457.9 MB)
17/08/11 03:04:38 INFO spark.SparkContext: Created broadcast 0 from flatMap at AvroDataConnector.scala:66
17/08/11 03:04:38 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 212.9 KB, free 445.4 KB)
17/08/11 03:04:38 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.6 KB, free 464.9 KB)
17/08/11 03:04:38 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.2:57662 (size: 19.6 KB, free: 457.8 MB)
17/08/11 03:04:38 INFO spark.SparkContext: Created broadcast 1 from hadoopFile at AvroRelation.scala:121
17/08/11 03:04:38 INFO mapred.FileInputFormat: Total input paths to process : 1
17/08/11 03:04:38 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:42
17/08/11 03:04:38 INFO scheduler.DAGScheduler: Got job 0 (count at ProfileCore.scala:42) with 2 output partitions
17/08/11 03:04:38 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (count at ProfileCore.scala:42)
17/08/11 03:04:38 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:38 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:38 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36), which has no missing parents
17/08/11 03:04:38 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.3 KB, free 478.3 KB)
17/08/11 03:04:38 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KB, free 484.5 KB)
17/08/11 03:04:38 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.2:57662 (size: 6.2 KB, free: 457.8 MB)
17/08/11 03:04:38 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:38 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36)
17/08/11 03:04:38 INFO cluster.YarnScheduler: Adding task set 0.0 with 2 tasks
17/08/11 03:04:38 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:40 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox:39818 (size: 6.2 KB, free: 511.1 MB)
17/08/11 03:04:41 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox:39818 (size: 19.6 KB, free: 511.1 MB)
17/08/11 03:04:42 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:42 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4248 ms on sandbox (1/2)
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 222 ms on sandbox (2/2)
17/08/11 03:04:43 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/08/11 03:04:43 INFO scheduler.DAGScheduler: ResultStage 0 (count at ProfileCore.scala:42) finished in 4.463 s
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Job 0 finished: count at ProfileCore.scala:42, took 4.475945 s
17/08/11 03:04:43 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:44
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Got job 1 (count at ProfileCore.scala:44) with 2 output partitions
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (count at ProfileCore.scala:44)
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43), which has no missing parents
17/08/11 03:04:43 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.7 KB, free 498.1 KB)
17/08/11 03:04:43 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.3 KB, free 504.4 KB)
17/08/11 03:04:43 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.2:57662 (size: 6.3 KB, free: 457.8 MB)
17/08/11 03:04:43 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43)
17/08/11 03:04:43 INFO cluster.YarnScheduler: Adding task set 1.0 with 2 tasks
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:43 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox:39818 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 168 ms on sandbox (1/2)
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 178 ms on sandbox (2/2)
17/08/11 03:04:43 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/08/11 03:04:43 INFO scheduler.DAGScheduler: ResultStage 1 (count at ProfileCore.scala:44) finished in 0.341 s
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Job 1 finished: count at ProfileCore.scala:44, took 0.351921 s
17/08/11 03:04:43 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:46
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Got job 2 (count at ProfileCore.scala:46) with 2 output partitions
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (count at ProfileCore.scala:46)
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45), which has no missing parents
17/08/11 03:04:43 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.7 KB, free 518.1 KB)
17/08/11 03:04:43 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.3 KB, free 524.4 KB)
17/08/11 03:04:43 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.2:57662 (size: 6.3 KB, free: 457.8 MB)
17/08/11 03:04:43 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45)
17/08/11 03:04:43 INFO cluster.YarnScheduler: Adding task set 2.0 with 2 tasks
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:43 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on sandbox:39818 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 154 ms on sandbox (1/2)
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 130 ms on sandbox (2/2)
17/08/11 03:04:43 INFO scheduler.DAGScheduler: ResultStage 2 (count at ProfileCore.scala:46) finished in 0.281 s
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Job 2 finished: count at ProfileCore.scala:46, took 0.288260 s
17/08/11 03:04:43 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/08/11 03:04:43 INFO persist.LoggerPersist: 1502420683809: calculation using time: 5219 ms
17/08/11 03:04:43 INFO persist.LoggerPersist: profileEnum_1502420661332_Amer-Indian-Eskimo result: 
match percentage: 0.9551303706888609
total count: 32561
miss count: 32250, match count: 311
17/08/11 03:04:43 INFO persist.HttpPersist: post to http://10.149.247.156:49200/griffin/accuracy response status: 201
17/08/11 03:04:43 INFO persist.LoggerPersist: profileEnum_1502420661332_Amer-Indian-Eskimo match records: 
17/08/11 03:04:43 INFO spark.SparkContext: Starting job: count at LoggerPersist.scala:65
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Got job 3 (count at LoggerPersist.scala:65) with 2 output partitions
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (count at LoggerPersist.scala:65)
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:04:43 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.1 KB, free 538.5 KB)
17/08/11 03:04:43 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 544.9 KB)
17/08/11 03:04:43 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.2:57662 (size: 6.4 KB, free: 457.8 MB)
17/08/11 03:04:43 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:43 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:04:43 INFO cluster.YarnScheduler: Adding task set 3.0 with 2 tasks
17/08/11 03:04:43 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:43 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on sandbox:39818 (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:04:44 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 167 ms on sandbox (1/2)
17/08/11 03:04:44 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 136 ms on sandbox (2/2)
17/08/11 03:04:44 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/08/11 03:04:44 INFO scheduler.DAGScheduler: ResultStage 3 (count at LoggerPersist.scala:65) finished in 0.301 s
17/08/11 03:04:44 INFO scheduler.DAGScheduler: Job 3 finished: count at LoggerPersist.scala:65, took 0.311288 s
17/08/11 03:04:44 INFO spark.SparkContext: Starting job: take at LoggerPersist.scala:68
17/08/11 03:04:44 INFO scheduler.DAGScheduler: Got job 4 (take at LoggerPersist.scala:68) with 1 output partitions
17/08/11 03:04:44 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (take at LoggerPersist.scala:68)
17/08/11 03:04:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:04:44 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:04:44 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:04:44 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.2 KB, free 559.1 KB)
17/08/11 03:04:44 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.5 KB, free 565.6 KB)
17/08/11 03:04:44 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.2:57662 (size: 6.5 KB, free: 457.8 MB)
17/08/11 03:04:44 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
17/08/11 03:04:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:04:44 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks
17/08/11 03:04:44 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:04:44 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on sandbox:39818 (size: 6.5 KB, free: 511.1 MB)
17/08/11 03:04:44 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 58 ms on sandbox (1/1)
17/08/11 03:04:44 INFO scheduler.DAGScheduler: ResultStage 4 (take at LoggerPersist.scala:68) finished in 0.059 s
17/08/11 03:04:44 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/08/11 03:04:44 INFO scheduler.DAGScheduler: Job 4 finished: take at LoggerPersist.scala:68, took 0.071711 s
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
Map($source['race'] -> Amer-Indian-Eskimo)
17/08/11 03:04:44 INFO persist.LoggerPersist: 1502420684232: persist using time: 423 ms
17/08/11 03:04:44 INFO persist.LoggerPersist: profileEnum_1502420661332_Amer-Indian-Eskimo finish
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL3/execution/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL3/execution,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL3/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL3,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
17/08/11 03:04:44 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
17/08/11 03:04:44 INFO ui.SparkUI: Stopped Spark web UI at http://172.17.0.2:4040
17/08/11 03:04:44 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
17/08/11 03:04:44 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
17/08/11 03:04:44 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
17/08/11 03:04:44 INFO cluster.YarnClientSchedulerBackend: Stopped
17/08/11 03:04:44 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/08/11 03:04:44 INFO storage.MemoryStore: MemoryStore cleared
17/08/11 03:04:44 INFO storage.BlockManager: BlockManager stopped
17/08/11 03:04:44 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/08/11 03:04:44 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/08/11 03:04:44 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/08/11 03:04:44 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/08/11 03:04:44 INFO spark.SparkContext: Successfully stopped SparkContext
17/08/11 03:04:44 INFO batch.Application$: calculation finished
17/08/11 03:04:44 INFO batch.Application$: [Ljava.lang.String;@412de677
17/08/11 03:04:44 INFO batch.Application$: env.json
17/08/11 03:04:44 INFO batch.Application$: {"name":"profileEnum_1502420684342_Other","type":"profile","source":{"type":"avro","version":"1.7","config":{"file.name":"hdfs:///griffin/data/enum-profiling-sample/test_src.avro"}},"evaluateRule":{"sampleRatio":1,"rules":"$source.race == 'Other'"}}
17/08/11 03:04:44 INFO batch.Application$: params validation pass
17/08/11 03:04:44 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/08/11 03:04:44 INFO spark.SparkContext: Running Spark version 1.6.0
17/08/11 03:04:44 WARN spark.SparkConf: 
SPARK_JAVA_OPTS was detected (set to '-Dspark.driver.port=53411').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
17/08/11 03:04:44 WARN spark.SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:04:44 WARN spark.SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.driver.port=53411' as a work-around.
17/08/11 03:04:44 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:04:44 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:04:44 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:04:44 INFO util.Utils: Successfully started service 'sparkDriver' on port 53411.
17/08/11 03:04:44 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/08/11 03:04:44 INFO Remoting: Starting remoting
17/08/11 03:04:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.17.0.2:53412]
17/08/11 03:04:44 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 53412.
17/08/11 03:04:44 INFO spark.SparkEnv: Registering MapOutputTracker
17/08/11 03:04:44 INFO spark.SparkEnv: Registering BlockManagerMaster
17/08/11 03:04:44 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-6bdd8e39-12e0-4ad6-903a-7045e08b5db0
17/08/11 03:04:44 INFO storage.MemoryStore: MemoryStore started with capacity 457.9 MB
17/08/11 03:04:44 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/08/11 03:04:44 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:04:44 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
17/08/11 03:04:44 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/08/11 03:04:44 INFO ui.SparkUI: Started SparkUI at http://172.17.0.2:4040
17/08/11 03:04:44 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-9d66a31c-4195-41a4-881e-5794d676feb7
17/08/11 03:04:44 INFO spark.HttpServer: Starting HTTP Server
17/08/11 03:04:44 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/08/11 03:04:44 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36654
17/08/11 03:04:44 INFO util.Utils: Successfully started service 'HTTP file server' on port 36654.
17/08/11 03:04:44 INFO spark.SparkContext: Added JAR file:/root/griffin-sample/enum-profiling-sample/sample/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar at http://172.17.0.2:36654/jars/griffin-profile-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1502420684875
17/08/11 03:04:44 INFO client.RMProxy: Connecting to ResourceManager at sandbox/172.17.0.2:8032
17/08/11 03:04:44 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
17/08/11 03:04:44 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
17/08/11 03:04:44 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
17/08/11 03:04:44 INFO yarn.Client: Setting up container launch context for our AM
17/08/11 03:04:44 INFO yarn.Client: Setting up the launch environment for our AM container
17/08/11 03:04:44 INFO yarn.Client: Preparing resources for our AM container
17/08/11 03:04:44 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs:/home/spark_lib/spark-assembly-1.6.0-hadoop2.6.0.jar
17/08/11 03:04:44 INFO yarn.Client: Uploading resource file:/apache/spark/conf/hive-site.xml -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0063/hive-site.xml
17/08/11 03:04:44 INFO yarn.Client: Uploading resource file:/tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/__spark_conf__8968957664288777480.zip -> hdfs://sandbox:9000/user/root/.sparkStaging/application_1500434006041_0063/__spark_conf__8968957664288777480.zip
17/08/11 03:04:45 INFO spark.SecurityManager: Changing view acls to: root
17/08/11 03:04:45 INFO spark.SecurityManager: Changing modify acls to: root
17/08/11 03:04:45 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/11 03:04:45 INFO yarn.Client: Submitting application 63 to ResourceManager
17/08/11 03:04:45 INFO impl.YarnClientImpl: Submitted application application_1500434006041_0063
17/08/11 03:04:46 INFO yarn.Client: Application report for application_1500434006041_0063 (state: ACCEPTED)
17/08/11 03:04:46 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1502420685031
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0063/
	 user: root
17/08/11 03:04:47 INFO yarn.Client: Application report for application_1500434006041_0063 (state: ACCEPTED)
17/08/11 03:04:48 INFO yarn.Client: Application report for application_1500434006041_0063 (state: ACCEPTED)
17/08/11 03:04:49 INFO yarn.Client: Application report for application_1500434006041_0063 (state: ACCEPTED)
17/08/11 03:04:50 INFO yarn.Client: Application report for application_1500434006041_0063 (state: ACCEPTED)
17/08/11 03:04:51 INFO yarn.Client: Application report for application_1500434006041_0063 (state: ACCEPTED)
17/08/11 03:04:51 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null)
17/08/11 03:04:51 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> sandbox, PROXY_URI_BASES -> http://sandbox:8088/proxy/application_1500434006041_0063), /proxy/application_1500434006041_0063
17/08/11 03:04:51 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
17/08/11 03:04:52 INFO yarn.Client: Application report for application_1500434006041_0063 (state: RUNNING)
17/08/11 03:04:52 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.17.0.2
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1502420685031
	 final status: UNDEFINED
	 tracking URL: http://sandbox:8088/proxy/application_1500434006041_0063/
	 user: root
17/08/11 03:04:52 INFO cluster.YarnClientSchedulerBackend: Application application_1500434006041_0063 has started running.
17/08/11 03:04:52 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42665.
17/08/11 03:04:52 INFO netty.NettyBlockTransferService: Server created on 42665
17/08/11 03:04:52 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/08/11 03:04:52 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.17.0.2:42665 with 457.9 MB RAM, BlockManagerId(driver, 172.17.0.2, 42665)
17/08/11 03:04:52 INFO storage.BlockManagerMaster: Registered BlockManager
17/08/11 03:04:58 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sandbox:41899) with ID 1
17/08/11 03:04:58 INFO storage.BlockManagerMasterEndpoint: Registering block manager sandbox:33627 with 511.1 MB RAM, BlockManagerId(1, sandbox, 33627)
17/08/11 03:04:58 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
17/08/11 03:04:58 INFO hive.HiveContext: Initializing execution hive, version 1.2.1
17/08/11 03:04:58 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:04:58 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:04:59 INFO hive.metastore: Mestastore configuration hive.metastore.warehouse.dir changed from file:/tmp/spark-93edef70-8d5b-47dc-a22e-4da7cef8a77a/metastore to file:/tmp/spark-180ad849-d9e3-493b-96c3-5b7c8324bfe1/metastore
17/08/11 03:04:59 INFO hive.metastore: Mestastore configuration javax.jdo.option.ConnectionURL changed from jdbc:derby:;databaseName=/tmp/spark-93edef70-8d5b-47dc-a22e-4da7cef8a77a/metastore;create=true to jdbc:derby:;databaseName=/tmp/spark-180ad849-d9e3-493b-96c3-5b7c8324bfe1/metastore;create=true
17/08/11 03:04:59 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
17/08/11 03:04:59 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=Shutting down the object store...	
17/08/11 03:04:59 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
17/08/11 03:04:59 INFO HiveMetaStore.audit: ugi=root	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
17/08/11 03:04:59 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/08/11 03:04:59 INFO metastore.ObjectStore: ObjectStore, initialize called
17/08/11 03:04:59 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/08/11 03:04:59 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/08/11 03:04:59 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/08/11 03:04:59 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:04:59 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:05:00 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:05:00 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/11 03:05:00 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/08/11 03:05:00 INFO metastore.ObjectStore: Initialized ObjectStore
17/08/11 03:05:00 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
17/08/11 03:05:01 INFO metastore.HiveMetaStore: Added admin role in metastore
17/08/11 03:05:01 INFO metastore.HiveMetaStore: Added public role in metastore
17/08/11 03:05:01 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
17/08/11 03:05:01 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/af6b14da-6e50-444e-811c-fb5226bc3180
17/08/11 03:05:01 INFO session.SessionState: Created local directory: /tmp/root/af6b14da-6e50-444e-811c-fb5226bc3180
17/08/11 03:05:01 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/af6b14da-6e50-444e-811c-fb5226bc3180/_tmp_space.db
17/08/11 03:05:01 INFO hive.HiveContext: default warehouse location is /user/hive/warehouse
17/08/11 03:05:01 INFO hive.HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/08/11 03:05:01 INFO client.ClientWrapper: Inspected Hadoop version: 2.6.0
17/08/11 03:05:01 INFO client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/08/11 03:05:01 INFO hive.metastore: Trying to connect to metastore with URI thrift://sandbox:9083
17/08/11 03:05:01 INFO hive.metastore: Connected to metastore.
17/08/11 03:05:01 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/195cbae1-c958-417b-b552-47f26985537e
17/08/11 03:05:01 INFO session.SessionState: Created local directory: /tmp/root/195cbae1-c958-417b-b552-47f26985537e
17/08/11 03:05:01 INFO session.SessionState: Created HDFS directory: /tmp/hive-root/root/195cbae1-c958-417b-b552-47f26985537e/_tmp_space.db
17/08/11 03:05:01 INFO persist.LoggerPersist: profileEnum_1502420684342_Other start
17/08/11 03:05:01 INFO avro.AvroRelation: Listing hdfs://sandbox:9000/griffin/data/enum-profiling-sample/test_src.avro on driver
17/08/11 03:05:01 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 212.9 KB, free 212.9 KB)
17/08/11 03:05:01 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.6 KB, free 232.5 KB)
17/08/11 03:05:01 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.2:42665 (size: 19.6 KB, free: 457.9 MB)
17/08/11 03:05:01 INFO spark.SparkContext: Created broadcast 0 from flatMap at AvroDataConnector.scala:66
17/08/11 03:05:01 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 212.9 KB, free 445.4 KB)
17/08/11 03:05:01 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.6 KB, free 464.9 KB)
17/08/11 03:05:01 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.2:42665 (size: 19.6 KB, free: 457.8 MB)
17/08/11 03:05:01 INFO spark.SparkContext: Created broadcast 1 from hadoopFile at AvroRelation.scala:121
17/08/11 03:05:01 INFO mapred.FileInputFormat: Total input paths to process : 1
17/08/11 03:05:01 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:42
17/08/11 03:05:01 INFO scheduler.DAGScheduler: Got job 0 (count at ProfileCore.scala:42) with 2 output partitions
17/08/11 03:05:01 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (count at ProfileCore.scala:42)
17/08/11 03:05:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:05:01 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:05:01 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36), which has no missing parents
17/08/11 03:05:01 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.3 KB, free 478.2 KB)
17/08/11 03:05:01 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KB, free 484.4 KB)
17/08/11 03:05:01 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.2:42665 (size: 6.2 KB, free: 457.8 MB)
17/08/11 03:05:01 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/08/11 03:05:01 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at map at ProfileCore.scala:36)
17/08/11 03:05:01 INFO cluster.YarnScheduler: Adding task set 0.0 with 2 tasks
17/08/11 03:05:01 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:03 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox:33627 (size: 6.2 KB, free: 511.1 MB)
17/08/11 03:05:04 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox:33627 (size: 19.6 KB, free: 511.1 MB)
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4292 ms on sandbox (1/2)
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 194 ms on sandbox (2/2)
17/08/11 03:05:06 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/08/11 03:05:06 INFO scheduler.DAGScheduler: ResultStage 0 (count at ProfileCore.scala:42) finished in 4.484 s
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Job 0 finished: count at ProfileCore.scala:42, took 4.494635 s
17/08/11 03:05:06 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:44
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Got job 1 (count at ProfileCore.scala:44) with 2 output partitions
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (count at ProfileCore.scala:44)
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43), which has no missing parents
17/08/11 03:05:06 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.6 KB, free 498.0 KB)
17/08/11 03:05:06 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.3 KB, free 504.3 KB)
17/08/11 03:05:06 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.2:42665 (size: 6.3 KB, free: 457.8 MB)
17/08/11 03:05:06 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at map at ProfileCore.scala:43)
17/08/11 03:05:06 INFO cluster.YarnScheduler: Adding task set 1.0 with 2 tasks
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:06 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox:33627 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 165 ms on sandbox (1/2)
17/08/11 03:05:06 INFO scheduler.DAGScheduler: ResultStage 1 (count at ProfileCore.scala:44) finished in 0.311 s
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Job 1 finished: count at ProfileCore.scala:44, took 0.319023 s
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 149 ms on sandbox (2/2)
17/08/11 03:05:06 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/08/11 03:05:06 INFO spark.SparkContext: Starting job: count at ProfileCore.scala:46
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Got job 2 (count at ProfileCore.scala:46) with 2 output partitions
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (count at ProfileCore.scala:46)
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45), which has no missing parents
17/08/11 03:05:06 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.6 KB, free 517.9 KB)
17/08/11 03:05:06 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.3 KB, free 524.2 KB)
17/08/11 03:05:06 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.2:42665 (size: 6.3 KB, free: 457.8 MB)
17/08/11 03:05:06 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at map at ProfileCore.scala:45)
17/08/11 03:05:06 INFO cluster.YarnScheduler: Adding task set 2.0 with 2 tasks
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:06 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on sandbox:33627 (size: 6.3 KB, free: 511.1 MB)
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 169 ms on sandbox (1/2)
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 134 ms on sandbox (2/2)
17/08/11 03:05:06 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/08/11 03:05:06 INFO scheduler.DAGScheduler: ResultStage 2 (count at ProfileCore.scala:46) finished in 0.301 s
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Job 2 finished: count at ProfileCore.scala:46, took 0.308983 s
17/08/11 03:05:06 INFO persist.LoggerPersist: 1502420706906: calculation using time: 5261 ms
17/08/11 03:05:06 INFO persist.LoggerPersist: profileEnum_1502420684342_Other result: 
match percentage: 0.8322840207610331
total count: 32561
miss count: 32290, match count: 271
17/08/11 03:05:06 INFO persist.HttpPersist: post to http://10.149.247.156:49200/griffin/accuracy response status: 201
17/08/11 03:05:06 INFO persist.LoggerPersist: profileEnum_1502420684342_Other match records: 
17/08/11 03:05:06 INFO spark.SparkContext: Starting job: count at LoggerPersist.scala:65
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Got job 3 (count at LoggerPersist.scala:65) with 2 output partitions
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (count at LoggerPersist.scala:65)
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:05:06 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.0 KB, free 538.2 KB)
17/08/11 03:05:06 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 544.6 KB)
17/08/11 03:05:06 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.2:42665 (size: 6.4 KB, free: 457.8 MB)
17/08/11 03:05:06 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/08/11 03:05:06 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:05:06 INFO cluster.YarnScheduler: Adding task set 3.0 with 2 tasks
17/08/11 03:05:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:06 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on sandbox:33627 (size: 6.4 KB, free: 511.1 MB)
17/08/11 03:05:07 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, sandbox, partition 1,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 158 ms on sandbox (1/2)
17/08/11 03:05:07 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 138 ms on sandbox (2/2)
17/08/11 03:05:07 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/08/11 03:05:07 INFO scheduler.DAGScheduler: ResultStage 3 (count at LoggerPersist.scala:65) finished in 0.293 s
17/08/11 03:05:07 INFO scheduler.DAGScheduler: Job 3 finished: count at LoggerPersist.scala:65, took 0.302375 s
17/08/11 03:05:07 INFO spark.SparkContext: Starting job: take at LoggerPersist.scala:68
17/08/11 03:05:07 INFO scheduler.DAGScheduler: Got job 4 (take at LoggerPersist.scala:68) with 1 output partitions
17/08/11 03:05:07 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (take at LoggerPersist.scala:68)
17/08/11 03:05:07 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/08/11 03:05:07 INFO scheduler.DAGScheduler: Missing parents: List()
17/08/11 03:05:07 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103), which has no missing parents
17/08/11 03:05:07 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.2 KB, free 558.8 KB)
17/08/11 03:05:07 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.5 KB, free 565.2 KB)
17/08/11 03:05:07 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.2:42665 (size: 6.5 KB, free: 457.8 MB)
17/08/11 03:05:07 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
17/08/11 03:05:07 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at map at BatchProfileAlgo.scala:103)
17/08/11 03:05:07 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks
17/08/11 03:05:07 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, sandbox, partition 0,NODE_LOCAL, 2372 bytes)
17/08/11 03:05:07 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on sandbox:33627 (size: 6.5 KB, free: 511.1 MB)
17/08/11 03:05:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 63 ms on sandbox (1/1)
17/08/11 03:05:07 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/08/11 03:05:07 INFO scheduler.DAGScheduler: ResultStage 4 (take at LoggerPersist.scala:68) finished in 0.062 s
17/08/11 03:05:07 INFO scheduler.DAGScheduler: Job 4 finished: take at LoggerPersist.scala:68, took 0.072110 s
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
Map($source['race'] -> Other)
17/08/11 03:05:07 INFO persist.LoggerPersist: 1502420707314: persist using time: 408 ms
17/08/11 03:05:07 INFO persist.LoggerPersist: profileEnum_1502420684342_Other finish
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static/sql,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL4/execution/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL4/execution,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL4/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQL4,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
17/08/11 03:05:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
17/08/11 03:05:07 INFO ui.SparkUI: Stopped Spark web UI at http://172.17.0.2:4040
17/08/11 03:05:07 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
17/08/11 03:05:07 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
17/08/11 03:05:07 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
17/08/11 03:05:07 INFO cluster.YarnClientSchedulerBackend: Stopped
17/08/11 03:05:07 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/08/11 03:05:07 INFO storage.MemoryStore: MemoryStore cleared
17/08/11 03:05:07 INFO storage.BlockManager: BlockManager stopped
17/08/11 03:05:07 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/08/11 03:05:07 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/08/11 03:05:07 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/08/11 03:05:07 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/08/11 03:05:07 INFO spark.SparkContext: Successfully stopped SparkContext
17/08/11 03:05:07 INFO batch.Application$: calculation finished
17/08/11 03:05:07 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/08/11 03:05:07 INFO output.LoggerPersist: ===========================================================
17/08/11 03:05:07 INFO output.LoggerPersist: race enum profile result:
17/08/11 03:05:07 INFO output.LoggerPersist: {Amer-Indian-Eskimo=0.009551303706888609, OTHER=0.0, Asian-Pac-Islander=0.03190933939375326, White=0.8542735173981143, Black=0.0959429992936335, Other=0.008322840207610331}
17/08/11 03:05:07 INFO output.LoggerPersist: ===========================================================
17/08/11 03:05:07 INFO output.HdfsPersist: ===========================================================
17/08/11 03:05:07 INFO output.HdfsPersist: create file hdfs:///griffin/data/enum-profiling-sample/result/1502420707669/_RESULT success!
duration: 125901
17/08/11 03:05:07 INFO output.HdfsPersist: ===========================================================
17/08/11 03:05:07 INFO util.ShutdownHookManager: Shutdown hook called
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-180ad849-d9e3-493b-96c3-5b7c8324bfe1
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-93edef70-8d5b-47dc-a22e-4da7cef8a77a
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-d870316b-dfd3-4ee7-956f-5e697d6eebc0
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-6069def1-f7dc-4ae0-b23d-bf17aa97a81e
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-331c69ca-6843-4ba3-8560-d0a1a4518de9
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-148a41fb-2309-4e9e-9a4e-d0b85af685f4
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-9889b9d1-d8d9-4076-b442-1b85d5fdf0dc
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-a60fca4a-e556-4cf5-b2b6-85b8a698ebb5
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-7946d297-5bce-4233-aedb-76c843004e75
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55/httpd-9d66a31c-4195-41a4-881e-5794d676feb7
17/08/11 03:05:07 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3489328b-f5de-44e7-9b21-57eb050dcd55
